{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2e549a-486a-4216-a218-bddbb824e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "# Import dataset from PyTorch Geometric\n",
    "dataset = Planetoid(root=\".\", name=\"Cora\")\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b824af92-705c-49f2-a3b6-6329b9eba8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cora()\n",
      "---------------\n",
      "Number of graphs: 1\n",
      "Number of nodes: 2708\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "Number of edges: 10556\n",
      "Edges are directed: False\n",
      "Graph has isolated nodes: False\n",
      "Graph has loops: False\n",
      "Average node degree: 3.90\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset: {dataset}')\n",
    "print('---------------')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of nodes: {data.x.shape[0]}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Edges are directed: {data.is_directed()}')\n",
    "print(f'Graph has isolated nodes: {data.has_isolated_nodes()}') # nodes not connected by edges\n",
    "print(f'Graph has loops: {data.has_self_loops()}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f473bf5-f779-4bf4-ad8f-676df18b6646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_mask.sum().item() # train_mask denotes against which nodes to train (140 nodes)\n",
    "data.val_mask.sum().item() # val_mask denotes which nodes to use for validation, e.g., to perform early stopping (500 nodes)\n",
    "data.test_mask.sum().item() # test_mask denotes against which nodes to test (1000 nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92483a23-4a13-44dd-8745-48dd7427dd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3.0: 26, 2.0: 25, 4.0: 22, 1.0: 20, 5.0: 15, 6.0: 11, 7.0: 4, 9.0: 4, 8.0: 3, 10.0: 3, 12.0: 2, 36.0: 1, 11.0: 1, 21.0: 1, 32.0: 1, 19.0: 1})\n"
     ]
    }
   ],
   "source": [
    "#Plot the number of nodes per node degree\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils import degree\n",
    "from collections import Counter\n",
    "\n",
    "# Calculate the degree of each node\n",
    "degrees = degree(data.edge_index[0]).numpy()\n",
    "# Select degrees of nodes in test set\n",
    "degrees=degrees[data.train_mask.numpy()]\n",
    "\n",
    "numbers = Counter(degrees)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "ax.set_xlabel('Node degree')\n",
    "ax.set_ylabel('Number of nodes')\n",
    "ax.set_xlim([-1, 25])\n",
    "plt.bar(numbers.keys(), numbers.values(),width=0.2, color='black', edgecolor='black')\n",
    "plt.title('Cora Graph Training Set: Number of Nodes by Node Degree')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Cora_Graph_Train_Node_Degrees.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d1f287-5eaf-4260-b1e4-b7c0ddc78288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, num_features, num_classes, hidden_channels, num_heads, heads_p_dropout,size_gat, p_dropout):\n",
    "        super(GAT, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        \n",
    "        self.convs.append(GATv2Conv(num_features, hidden_channels, heads=num_heads,dropout=heads_p_dropout))\n",
    "\n",
    "        for i in range(size_gat):\n",
    "            self.convs.append(GATv2Conv(hidden_channels*num_heads, hidden_channels, heads=num_heads))\n",
    "\n",
    "        #add dropout layer\n",
    "        self.dropout = nn.Dropout(p=p_dropout)\n",
    "\n",
    "        # Output layer\n",
    "        self.convs.append(GATv2Conv(hidden_channels*num_heads, num_classes, heads=1))   # concat=False means that the \n",
    "                                                                                    # multihead attentions are averaged\n",
    "        self.act = F.leaky_relu\n",
    "        #self.act = F.elu\n",
    "        \n",
    "    # Model with leading dropout\n",
    "    # def forward(self, x, edge_index):\n",
    "    #     for conv in self.convs:\n",
    "    #         x = self.dropout(x)\n",
    "    #         x = conv(x, edge_index)\n",
    "\n",
    "    #         if conv != self.convs[-1]:\n",
    "    #             x = self.act(x)\n",
    "\n",
    "    #     return F.softmax(x, dim=1)\n",
    "\n",
    "    # Model w/o leading dropout\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.convs:\n",
    "            if conv == self.convs[0]:\n",
    "                x = conv(x, edge_index)\n",
    "                x = self.act(x)\n",
    "            elif conv in self.convs[1:-2]:\n",
    "                x = self.dropout(x)\n",
    "                x = conv(x, edge_index)\n",
    "                x = self.act(x)\n",
    "            else:\n",
    "                x = self.dropout(x)\n",
    "                x = conv(x, edge_index)\n",
    "\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b22b9334-7244-4411-a6a4-c78b9ad8f55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-01 12:03:18,084]\u001b[0m A new study created in memory with name: no-name-3dce8947-2cb8-4705-8ff1-5d0640bd9228\u001b[0m\n",
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\progress_bar.py:56: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c278c994af479ba22772cd07ecb199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 79.40%\n",
      "\u001b[32m[I 2023-12-01 12:03:23,117]\u001b[0m Trial 0 finished with value: 0.794 and parameters: {'lr': 0.004502566252914796, 'hidden_channels': 32, 'hidden_layers': 0, 'p_dropout': 0.5841132205051996, 'batch_size': 140, 'epochs': 20, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.006154776247554489, 'num_heads': 8, 'heads_p_dropout': 0.4254030482286464}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 72.80%\n",
      "\u001b[32m[I 2023-12-01 12:03:32,421]\u001b[0m Trial 3 finished with value: 0.728 and parameters: {'lr': 0.001230394611525046, 'hidden_channels': 64, 'hidden_layers': 0, 'p_dropout': 0.5083316326701547, 'batch_size': 140, 'epochs': 70, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.006563041666574694, 'num_heads': 4, 'heads_p_dropout': 0.5261953115051189}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 78.20%\n",
      "\u001b[32m[I 2023-12-01 12:03:35,802]\u001b[0m Trial 2 finished with value: 0.782 and parameters: {'lr': 0.0016117431989144924, 'hidden_channels': 16, 'hidden_layers': 0, 'p_dropout': 0.4588459453216196, 'batch_size': 140, 'epochs': 70, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0064249733726712745, 'num_heads': 16, 'heads_p_dropout': 0.4598957078446265}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 15.80%\n",
      "\u001b[32m[I 2023-12-01 12:03:41,533]\u001b[0m Trial 5 finished with value: 0.158 and parameters: {'lr': 8.140761198755991e-05, 'hidden_channels': 16, 'hidden_layers': 2, 'p_dropout': 0.6817617512795137, 'batch_size': 140, 'epochs': 60, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0086742580222292, 'num_heads': 4, 'heads_p_dropout': 0.3074780862463606}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 74.20%\n",
      "\u001b[32m[I 2023-12-01 12:03:55,368]\u001b[0m Trial 6 finished with value: 0.742 and parameters: {'lr': 0.009016260370527088, 'hidden_channels': 64, 'hidden_layers': 1, 'p_dropout': 0.6160422745522731, 'batch_size': 140, 'epochs': 40, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0003507133833767252, 'num_heads': 8, 'heads_p_dropout': 0.23895600707050577}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 41.40%\n",
      "\u001b[32m[I 2023-12-01 12:04:02,313]\u001b[0m Trial 1 finished with value: 0.414 and parameters: {'lr': 0.0003005153197293373, 'hidden_channels': 8, 'hidden_layers': 2, 'p_dropout': 0.617107509616511, 'batch_size': 140, 'epochs': 120, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0017418226723899949, 'num_heads': 4, 'heads_p_dropout': 0.4507596419240252}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 28.00%\n",
      "\u001b[32m[I 2023-12-01 12:04:04,333]\u001b[0m Trial 7 finished with value: 0.28 and parameters: {'lr': 6.730527256101994e-05, 'hidden_channels': 32, 'hidden_layers': 0, 'p_dropout': 0.6153320970945599, 'batch_size': 140, 'epochs': 90, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.008568563049317253, 'num_heads': 8, 'heads_p_dropout': 0.30156340209690624}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 39.40%\n",
      "\u001b[32m[I 2023-12-01 12:04:10,732]\u001b[0m Trial 8 finished with value: 0.394 and parameters: {'lr': 0.00030673243121785373, 'hidden_channels': 128, 'hidden_layers': 2, 'p_dropout': 0.6731994579889855, 'batch_size': 140, 'epochs': 20, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0037002252220218208, 'num_heads': 8, 'heads_p_dropout': 0.2680480293679655}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 75.20%\n",
      "\u001b[32m[I 2023-12-01 12:04:11,308]\u001b[0m Trial 4 finished with value: 0.752 and parameters: {'lr': 0.0016243590974230632, 'hidden_channels': 32, 'hidden_layers': 1, 'p_dropout': 0.632223404515701, 'batch_size': 140, 'epochs': 120, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.007097607053147957, 'num_heads': 8, 'heads_p_dropout': 0.38871791000578904}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 17.00%\n",
      "\u001b[32m[I 2023-12-01 12:04:12,893]\u001b[0m Trial 11 finished with value: 0.17 and parameters: {'lr': 0.00017627095651619773, 'hidden_channels': 8, 'hidden_layers': 1, 'p_dropout': 0.43082890235628357, 'batch_size': 140, 'epochs': 30, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.003418017852835346, 'num_heads': 4, 'heads_p_dropout': 0.10351152063149681}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 32.40%\n",
      "\u001b[32m[I 2023-12-01 12:04:14,724]\u001b[0m Trial 9 finished with value: 0.324 and parameters: {'lr': 3.3819200588071776e-05, 'hidden_channels': 32, 'hidden_layers': 0, 'p_dropout': 0.5174568909548178, 'batch_size': 140, 'epochs': 90, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005051808980952882, 'num_heads': 4, 'heads_p_dropout': 0.5946272781432118}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 30.20%\n",
      "\u001b[32m[I 2023-12-01 12:04:28,196]\u001b[0m Trial 10 finished with value: 0.302 and parameters: {'lr': 4.2647881104596375e-05, 'hidden_channels': 16, 'hidden_layers': 0, 'p_dropout': 0.44312048681820315, 'batch_size': 140, 'epochs': 90, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.001645119789529942, 'num_heads': 8, 'heads_p_dropout': 0.45319492278474893}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 74.40%\n",
      "\u001b[32m[I 2023-12-01 12:05:22,894]\u001b[0m Trial 12 finished with value: 0.744 and parameters: {'lr': 0.005158482733605014, 'hidden_channels': 128, 'hidden_layers': 0, 'p_dropout': 0.6066555398823607, 'batch_size': 140, 'epochs': 80, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0060276908356067405, 'num_heads': 8, 'heads_p_dropout': 0.12020223494258378}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 78.00%\n",
      "\u001b[32m[I 2023-12-01 12:05:24,338]\u001b[0m Trial 15 finished with value: 0.78 and parameters: {'lr': 0.0043657927677245275, 'hidden_channels': 16, 'hidden_layers': 0, 'p_dropout': 0.43167451238864685, 'batch_size': 140, 'epochs': 80, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.00985399181089579, 'num_heads': 16, 'heads_p_dropout': 0.6349777307903997}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 60.20%\n",
      "\u001b[32m[I 2023-12-01 12:06:38,994]\u001b[0m Trial 18 finished with value: 0.602 and parameters: {'lr': 0.0011558071434970378, 'hidden_channels': 256, 'hidden_layers': 0, 'p_dropout': 0.5495600777603367, 'batch_size': 140, 'epochs': 20, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005385266102386712, 'num_heads': 16, 'heads_p_dropout': 0.6889568457166292}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 23.80%\n",
      "\u001b[32m[I 2023-12-01 12:06:46,681]\u001b[0m Trial 13 finished with value: 0.238 and parameters: {'lr': 3.4893035844948245e-05, 'hidden_channels': 16, 'hidden_layers': 2, 'p_dropout': 0.6576603042181213, 'batch_size': 140, 'epochs': 90, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.00901862879795728, 'num_heads': 4, 'heads_p_dropout': 0.3660301072654908}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 77.80%\n",
      "\u001b[32m[I 2023-12-01 12:06:57,557]\u001b[0m Trial 16 finished with value: 0.778 and parameters: {'lr': 0.003525065100500933, 'hidden_channels': 256, 'hidden_layers': 0, 'p_dropout': 0.5564871185388786, 'batch_size': 140, 'epochs': 50, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.006509650125604434, 'num_heads': 16, 'heads_p_dropout': 0.6731345280762997}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 76.80%\n",
      "\u001b[32m[I 2023-12-01 12:09:23,211]\u001b[0m Trial 17 finished with value: 0.768 and parameters: {'lr': 0.001689761837022511, 'hidden_channels': 256, 'hidden_layers': 0, 'p_dropout': 0.5454757138805374, 'batch_size': 140, 'epochs': 70, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.009637957561203964, 'num_heads': 16, 'heads_p_dropout': 0.61595060727181}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 27.40%\n",
      "\u001b[32m[I 2023-12-01 12:09:52,504]\u001b[0m Trial 21 finished with value: 0.274 and parameters: {'lr': 1.350401987300251e-05, 'hidden_channels': 32, 'hidden_layers': 0, 'p_dropout': 0.40994135470091475, 'batch_size': 140, 'epochs': 100, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.007385549279174438, 'num_heads': 16, 'heads_p_dropout': 0.5396356771720484}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 35.00%\n",
      "\u001b[32m[I 2023-12-01 12:10:04,997]\u001b[0m Trial 14 finished with value: 0.35 and parameters: {'lr': 1.7747186185598197e-05, 'hidden_channels': 256, 'hidden_layers': 0, 'p_dropout': 0.5470786011843539, 'batch_size': 140, 'epochs': 110, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.00993660818325022, 'num_heads': 16, 'heads_p_dropout': 0.6938957713456421}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 58.40%\n",
      "\u001b[32m[I 2023-12-01 12:10:21,297]\u001b[0m Trial 24 finished with value: 0.584 and parameters: {'lr': 0.0006035228857454043, 'hidden_channels': 32, 'hidden_layers': 1, 'p_dropout': 0.47477911872558193, 'batch_size': 140, 'epochs': 10, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.00765612822047829, 'num_heads': 16, 'heads_p_dropout': 0.4614832721000455}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 76.00%\n",
      "\u001b[32m[I 2023-12-01 12:10:32,661]\u001b[0m Trial 20 finished with value: 0.76 and parameters: {'lr': 0.002111670305860345, 'hidden_channels': 256, 'hidden_layers': 0, 'p_dropout': 0.4633994421237496, 'batch_size': 140, 'epochs': 70, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0076299809589949405, 'num_heads': 16, 'heads_p_dropout': 0.5080503972198218}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 23.60%\n",
      "\u001b[32m[I 2023-12-01 12:10:33,616]\u001b[0m Trial 19 finished with value: 0.236 and parameters: {'lr': 1.3675113964153546e-05, 'hidden_channels': 256, 'hidden_layers': 0, 'p_dropout': 0.4004154307023642, 'batch_size': 140, 'epochs': 70, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.007385008839988917, 'num_heads': 16, 'heads_p_dropout': 0.5048475783537292}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 17.60%\n",
      "\u001b[32m[I 2023-12-01 12:10:47,386]\u001b[0m Trial 22 finished with value: 0.176 and parameters: {'lr': 1.0367326560892603e-05, 'hidden_channels': 32, 'hidden_layers': 0, 'p_dropout': 0.40594830619669475, 'batch_size': 140, 'epochs': 100, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.007546276141344381, 'num_heads': 16, 'heads_p_dropout': 0.505438502606996}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 77.20%\n",
      "\u001b[32m[I 2023-12-01 12:10:51,398]\u001b[0m Trial 25 finished with value: 0.772 and parameters: {'lr': 0.0031801571685081023, 'hidden_channels': 16, 'hidden_layers': 0, 'p_dropout': 0.40036083024951985, 'batch_size': 140, 'epochs': 80, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.007901688294843789, 'num_heads': 16, 'heads_p_dropout': 0.5187299416547761}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 76.40%\n",
      "\u001b[32m[I 2023-12-01 12:10:55,362]\u001b[0m Trial 26 finished with value: 0.764 and parameters: {'lr': 0.009851490708156333, 'hidden_channels': 16, 'hidden_layers': 0, 'p_dropout': 0.4246304226157048, 'batch_size': 140, 'epochs': 80, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.008067002995114314, 'num_heads': 16, 'heads_p_dropout': 0.5878245540010132}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 76.40%\n",
      "\u001b[32m[I 2023-12-01 12:10:56,029]\u001b[0m Trial 27 finished with value: 0.764 and parameters: {'lr': 0.004149715871320537, 'hidden_channels': 16, 'hidden_layers': 0, 'p_dropout': 0.47267216421164143, 'batch_size': 140, 'epochs': 80, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005720632539225887, 'num_heads': 16, 'heads_p_dropout': 0.5822875759021878}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 63.80%\n",
      "\u001b[32m[I 2023-12-01 12:10:58,824]\u001b[0m Trial 30 finished with value: 0.638 and parameters: {'lr': 0.004663005039791747, 'hidden_channels': 16, 'hidden_layers': 0, 'p_dropout': 0.4547852335540218, 'batch_size': 140, 'epochs': 20, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.009241655542794807, 'num_heads': 8, 'heads_p_dropout': 0.4252755753348664}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 20.60%\n",
      "\u001b[32m[I 2023-12-01 12:11:01,610]\u001b[0m Trial 32 finished with value: 0.206 and parameters: {'lr': 0.0008175210404200101, 'hidden_channels': 16, 'hidden_layers': 1, 'p_dropout': 0.49068238142544235, 'batch_size': 140, 'epochs': 10, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0046849061071254005, 'num_heads': 8, 'heads_p_dropout': 0.6509156227089881}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 48.80%\n",
      "\u001b[32m[I 2023-12-01 12:11:03,759]\u001b[0m Trial 31 finished with value: 0.488 and parameters: {'lr': 0.005476758494351832, 'hidden_channels': 16, 'hidden_layers': 2, 'p_dropout': 0.4484635094440384, 'batch_size': 140, 'epochs': 20, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0045010483801341886, 'num_heads': 8, 'heads_p_dropout': 0.629927615387484}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 78.00%\n",
      "\u001b[32m[I 2023-12-01 12:11:04,979]\u001b[0m Trial 29 finished with value: 0.78 and parameters: {'lr': 0.008866581683731084, 'hidden_channels': 16, 'hidden_layers': 0, 'p_dropout': 0.4791207008873486, 'batch_size': 140, 'epochs': 80, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0058959525855764765, 'num_heads': 8, 'heads_p_dropout': 0.5969126979102414}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 75.80%\n",
      "\u001b[32m[I 2023-12-01 12:11:06,534]\u001b[0m Trial 28 finished with value: 0.758 and parameters: {'lr': 0.00864988697869746, 'hidden_channels': 16, 'hidden_layers': 0, 'p_dropout': 0.4693808006601571, 'batch_size': 140, 'epochs': 80, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0057365548931521725, 'num_heads': 16, 'heads_p_dropout': 0.5921929020811177}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 56.60%\n",
      "\u001b[32m[I 2023-12-01 12:11:08,278]\u001b[0m Trial 23 finished with value: 0.566 and parameters: {'lr': 0.0005789465954159444, 'hidden_channels': 16, 'hidden_layers': 1, 'p_dropout': 0.4748204446049018, 'batch_size': 140, 'epochs': 110, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.007859476853119652, 'num_heads': 16, 'heads_p_dropout': 0.4678373990088583}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 71.80%\n",
      "\u001b[32m[I 2023-12-01 12:11:12,283]\u001b[0m Trial 36 finished with value: 0.718 and parameters: {'lr': 0.0027479641942969608, 'hidden_channels': 8, 'hidden_layers': 0, 'p_dropout': 0.42666429739502587, 'batch_size': 140, 'epochs': 50, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.00669845353175961, 'num_heads': 8, 'heads_p_dropout': 0.5526407919677637}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 78.20%\n",
      "\u001b[32m[I 2023-12-01 12:11:15,029]\u001b[0m Trial 35 finished with value: 0.782 and parameters: {'lr': 0.0025537214164009516, 'hidden_channels': 8, 'hidden_layers': 0, 'p_dropout': 0.43611018739180357, 'batch_size': 140, 'epochs': 80, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0064478321792865246, 'num_heads': 8, 'heads_p_dropout': 0.5629003211829376}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 25.00%\n",
      "\u001b[32m[I 2023-12-01 12:11:15,311]\u001b[0m Trial 34 finished with value: 0.25 and parameters: {'lr': 0.0026271490214769735, 'hidden_channels': 8, 'hidden_layers': 2, 'p_dropout': 0.5828898092447928, 'batch_size': 140, 'epochs': 30, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.006586213511287131, 'num_heads': 16, 'heads_p_dropout': 0.5664838130460994}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 77.60%\n",
      "\u001b[32m[I 2023-12-01 12:11:28,421]\u001b[0m Trial 37 finished with value: 0.776 and parameters: {'lr': 0.0025668502213000294, 'hidden_channels': 8, 'hidden_layers': 0, 'p_dropout': 0.4333919702843186, 'batch_size': 140, 'epochs': 120, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.006567626194443275, 'num_heads': 8, 'heads_p_dropout': 0.553655274293631}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 79.00%\n",
      "\u001b[32m[I 2023-12-01 12:11:31,258]\u001b[0m Trial 38 finished with value: 0.79 and parameters: {'lr': 0.0021954630293064175, 'hidden_channels': 128, 'hidden_layers': 0, 'p_dropout': 0.4982605169038479, 'batch_size': 140, 'epochs': 40, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0063841515162036755, 'num_heads': 8, 'heads_p_dropout': 0.6457233999625464}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 59.40%\n",
      "\u001b[32m[I 2023-12-01 12:11:41,378]\u001b[0m Trial 41 finished with value: 0.594 and parameters: {'lr': 0.0015343860514416146, 'hidden_channels': 8, 'hidden_layers': 0, 'p_dropout': 0.4986080905566189, 'batch_size': 140, 'epochs': 60, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.006998063036025106, 'num_heads': 8, 'heads_p_dropout': 0.4145069501475695}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 46.00%\n",
      "\u001b[32m[I 2023-12-01 12:11:42,268]\u001b[0m Trial 33 finished with value: 0.46 and parameters: {'lr': 0.0027417681283714856, 'hidden_channels': 8, 'hidden_layers': 2, 'p_dropout': 0.44068974472948164, 'batch_size': 140, 'epochs': 110, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.008586561251514201, 'num_heads': 8, 'heads_p_dropout': 0.6289624042352536}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 78.40%\n",
      "\u001b[32m[I 2023-12-01 12:12:05,513]\u001b[0m Trial 40 finished with value: 0.784 and parameters: {'lr': 0.0018087849038960744, 'hidden_channels': 64, 'hidden_layers': 0, 'p_dropout': 0.43853626819894836, 'batch_size': 140, 'epochs': 120, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.008443534284119602, 'num_heads': 8, 'heads_p_dropout': 0.6404824029474383}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 70.60%\n",
      "\u001b[32m[I 2023-12-01 12:12:16,434]\u001b[0m Trial 44 finished with value: 0.706 and parameters: {'lr': 0.0010672101535708065, 'hidden_channels': 128, 'hidden_layers': 0, 'p_dropout': 0.45389874493663357, 'batch_size': 140, 'epochs': 40, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.006262478153976015, 'num_heads': 8, 'heads_p_dropout': 0.3765063301878383}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 76.20%\n",
      "\u001b[32m[I 2023-12-01 12:12:37,998]\u001b[0m Trial 39 finished with value: 0.762 and parameters: {'lr': 0.0024265966002663727, 'hidden_channels': 8, 'hidden_layers': 2, 'p_dropout': 0.43610995783535866, 'batch_size': 140, 'epochs': 120, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.006841297555238063, 'num_heads': 8, 'heads_p_dropout': 0.5594516356728636}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 51.00%\n",
      "\u001b[32m[I 2023-12-01 12:12:55,995]\u001b[0m Trial 42 finished with value: 0.51 and parameters: {'lr': 0.0014514544917800544, 'hidden_channels': 128, 'hidden_layers': 2, 'p_dropout': 0.49324690109190356, 'batch_size': 140, 'epochs': 40, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.007064448409242096, 'num_heads': 8, 'heads_p_dropout': 0.40741805664835484}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 57.00%\n",
      "\u001b[32m[I 2023-12-01 12:13:05,928]\u001b[0m Trial 43 finished with value: 0.57 and parameters: {'lr': 0.0012152398566322687, 'hidden_channels': 128, 'hidden_layers': 2, 'p_dropout': 0.5147329446086206, 'batch_size': 140, 'epochs': 40, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0061811640581049656, 'num_heads': 8, 'heads_p_dropout': 0.37502325982432627}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 79.00%\n",
      "\u001b[32m[I 2023-12-01 12:13:17,340]\u001b[0m Trial 45 finished with value: 0.79 and parameters: {'lr': 0.001205812241865269, 'hidden_channels': 64, 'hidden_layers': 0, 'p_dropout': 0.5125149028212348, 'batch_size': 140, 'epochs': 120, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.007073951232581218, 'num_heads': 8, 'heads_p_dropout': 0.4798358356219987}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 75.60%\n",
      "\u001b[32m[I 2023-12-01 12:13:21,139]\u001b[0m Trial 46 finished with value: 0.756 and parameters: {'lr': 0.0021452437833317413, 'hidden_channels': 64, 'hidden_layers': 0, 'p_dropout': 0.5173229809730587, 'batch_size': 140, 'epochs': 120, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0069010197738269205, 'num_heads': 8, 'heads_p_dropout': 0.6688083419233333}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 76.60%\n",
      "\u001b[32m[I 2023-12-01 12:13:34,132]\u001b[0m Trial 47 finished with value: 0.766 and parameters: {'lr': 0.0016354656302801263, 'hidden_channels': 64, 'hidden_layers': 0, 'p_dropout': 0.5202910310644956, 'batch_size': 140, 'epochs': 120, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.006119562981213793, 'num_heads': 8, 'heads_p_dropout': 0.6579856111123112}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 78.00%\n",
      "\u001b[32m[I 2023-12-01 12:13:37,867]\u001b[0m Trial 48 finished with value: 0.78 and parameters: {'lr': 0.0018834886434975597, 'hidden_channels': 64, 'hidden_layers': 0, 'p_dropout': 0.5142781645668749, 'batch_size': 140, 'epochs': 120, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.00833776052602343, 'num_heads': 4, 'heads_p_dropout': 0.6444762663474618}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 76.00%\n",
      "\u001b[32m[I 2023-12-01 12:13:41,942]\u001b[0m Trial 49 finished with value: 0.76 and parameters: {'lr': 0.0019618985018030363, 'hidden_channels': 64, 'hidden_layers': 0, 'p_dropout': 0.45492140594362884, 'batch_size': 140, 'epochs': 120, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.008282487267353523, 'num_heads': 4, 'heads_p_dropout': 0.6647505906777239}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 78.20%\n",
      "\u001b[32m[I 2023-12-01 12:13:52,964]\u001b[0m Trial 50 finished with value: 0.782 and parameters: {'lr': 0.0019283197128053136, 'hidden_channels': 64, 'hidden_layers': 0, 'p_dropout': 0.5235536358616264, 'batch_size': 140, 'epochs': 120, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.007043479152817883, 'num_heads': 4, 'heads_p_dropout': 0.4680529919694035}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 77.60%\n",
      "\u001b[32m[I 2023-12-01 12:13:54,447]\u001b[0m Trial 51 finished with value: 0.776 and parameters: {'lr': 0.0017042641429793129, 'hidden_channels': 64, 'hidden_layers': 0, 'p_dropout': 0.530465570221566, 'batch_size': 140, 'epochs': 120, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.008187427996936416, 'num_heads': 4, 'heads_p_dropout': 0.4796336616941192}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 75.60%\n",
      "\u001b[32m[I 2023-12-01 12:14:14,425]\u001b[0m Trial 53 finished with value: 0.756 and parameters: {'lr': 0.005786698892428948, 'hidden_channels': 64, 'hidden_layers': 1, 'p_dropout': 0.4892430748835511, 'batch_size': 140, 'epochs': 70, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0051889522256302655, 'num_heads': 4, 'heads_p_dropout': 0.34970895252687073}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 76.60%\n",
      "\u001b[32m[I 2023-12-01 12:14:16,322]\u001b[0m Trial 56 finished with value: 0.766 and parameters: {'lr': 0.0037080159066930976, 'hidden_channels': 32, 'hidden_layers': 0, 'p_dropout': 0.48267836817654025, 'batch_size': 140, 'epochs': 70, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005520775178571191, 'num_heads': 8, 'heads_p_dropout': 0.4280836223957693}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 76.60%\n",
      "\u001b[32m[I 2023-12-01 12:14:22,738]\u001b[0m Trial 55 finished with value: 0.766 and parameters: {'lr': 0.003657927711155215, 'hidden_channels': 64, 'hidden_layers': 0, 'p_dropout': 0.48995283717375, 'batch_size': 140, 'epochs': 70, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005450430193717248, 'num_heads': 8, 'heads_p_dropout': 0.4883033652482772}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 78.40%\n",
      "\u001b[32m[I 2023-12-01 12:14:31,004]\u001b[0m Trial 54 finished with value: 0.784 and parameters: {'lr': 0.0009121391707240818, 'hidden_channels': 64, 'hidden_layers': 1, 'p_dropout': 0.5321853128655246, 'batch_size': 140, 'epochs': 70, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005349330359504706, 'num_heads': 8, 'heads_p_dropout': 0.33264871499722004}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 57.20%\n",
      "\u001b[32m[I 2023-12-01 12:14:36,987]\u001b[0m Trial 59 finished with value: 0.572 and parameters: {'lr': 0.0009025195183140174, 'hidden_channels': 128, 'hidden_layers': 0, 'p_dropout': 0.4580475544175325, 'batch_size': 140, 'epochs': 20, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.007239406772496467, 'num_heads': 8, 'heads_p_dropout': 0.5213399170991607}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 76.20%\n",
      "\u001b[32m[I 2023-12-01 12:14:39,893]\u001b[0m Trial 52 finished with value: 0.762 and parameters: {'lr': 0.0008148079441126733, 'hidden_channels': 64, 'hidden_layers': 1, 'p_dropout': 0.5033349072006441, 'batch_size': 140, 'epochs': 120, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0081473103865143, 'num_heads': 4, 'heads_p_dropout': 0.48620178814151543}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 79.00%\n",
      "\u001b[32m[I 2023-12-01 12:14:41,919]\u001b[0m Trial 57 finished with value: 0.79 and parameters: {'lr': 0.0035148206817066023, 'hidden_channels': 32, 'hidden_layers': 0, 'p_dropout': 0.46158021032047286, 'batch_size': 140, 'epochs': 60, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005536474383164867, 'num_heads': 8, 'heads_p_dropout': 0.4362410541311367}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 77.80%\n",
      "\u001b[32m[I 2023-12-01 12:14:55,379]\u001b[0m Trial 58 finished with value: 0.778 and parameters: {'lr': 0.0008992189314316935, 'hidden_channels': 128, 'hidden_layers': 0, 'p_dropout': 0.46376002228363794, 'batch_size': 140, 'epochs': 60, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.006357853079487593, 'num_heads': 8, 'heads_p_dropout': 0.44496029800324943}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 58.80%\n",
      "\u001b[32m[I 2023-12-01 12:15:15,430]\u001b[0m Trial 60 finished with value: 0.588 and parameters: {'lr': 0.0009076405436083643, 'hidden_channels': 64, 'hidden_layers': 1, 'p_dropout': 0.5074165797907666, 'batch_size': 140, 'epochs': 60, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.006030614130543649, 'num_heads': 8, 'heads_p_dropout': 0.4453873140881327}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 65.20%\n",
      "\u001b[32m[I 2023-12-01 12:15:16,336]\u001b[0m Trial 62 finished with value: 0.652 and parameters: {'lr': 0.0013638592410806017, 'hidden_channels': 32, 'hidden_layers': 1, 'p_dropout': 0.5039314552770927, 'batch_size': 140, 'epochs': 60, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.006220415099310584, 'num_heads': 8, 'heads_p_dropout': 0.4402753794028507}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 78.40%\n",
      "\u001b[32m[I 2023-12-01 12:15:19,274]\u001b[0m Trial 63 finished with value: 0.784 and parameters: {'lr': 0.0012625305737144971, 'hidden_channels': 32, 'hidden_layers': 1, 'p_dropout': 0.5022490732256951, 'batch_size': 140, 'epochs': 60, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.004896101490480132, 'num_heads': 8, 'heads_p_dropout': 0.43586999761909256}. Best is trial 0 with value: 0.794.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 81.00%\n",
      "\u001b[32m[I 2023-12-01 12:15:22,108]\u001b[0m Trial 61 finished with value: 0.81 and parameters: {'lr': 0.0013191168503116166, 'hidden_channels': 64, 'hidden_layers': 1, 'p_dropout': 0.5048414017214051, 'batch_size': 140, 'epochs': 60, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005908460006339683, 'num_heads': 8, 'heads_p_dropout': 0.4423211437386582}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 64.80%\n",
      "\u001b[32m[I 2023-12-01 12:15:26,338]\u001b[0m Trial 64 finished with value: 0.648 and parameters: {'lr': 0.0013372003277935768, 'hidden_channels': 32, 'hidden_layers': 1, 'p_dropout': 0.502829790516717, 'batch_size': 140, 'epochs': 60, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005928598117101327, 'num_heads': 8, 'heads_p_dropout': 0.6982037579114546}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 78.80%\n",
      "\u001b[32m[I 2023-12-01 12:15:49,076]\u001b[0m Trial 66 finished with value: 0.788 and parameters: {'lr': 0.003139408341632013, 'hidden_channels': 32, 'hidden_layers': 1, 'p_dropout': 0.5342438144915399, 'batch_size': 140, 'epochs': 70, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.004955809942443973, 'num_heads': 8, 'heads_p_dropout': 0.38947760168798734}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 59.40%\n",
      "\u001b[32m[I 2023-12-01 12:15:49,480]\u001b[0m Trial 67 finished with value: 0.594 and parameters: {'lr': 0.0005885441448669, 'hidden_channels': 32, 'hidden_layers': 1, 'p_dropout': 0.5366721052555525, 'batch_size': 140, 'epochs': 60, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.004988167862896377, 'num_heads': 8, 'heads_p_dropout': 0.40237513030737576}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 78.20%\n",
      "\u001b[32m[I 2023-12-01 12:15:56,662]\u001b[0m Trial 65 finished with value: 0.782 and parameters: {'lr': 0.0011905747256671186, 'hidden_channels': 32, 'hidden_layers': 1, 'p_dropout': 0.5037618526670238, 'batch_size': 140, 'epochs': 90, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0049147646538889745, 'num_heads': 8, 'heads_p_dropout': 0.3941867784881426}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 57.40%\n",
      "\u001b[32m[I 2023-12-01 12:16:04,965]\u001b[0m Trial 68 finished with value: 0.574 and parameters: {'lr': 0.0005693169140658763, 'hidden_channels': 32, 'hidden_layers': 1, 'p_dropout': 0.5398714057182785, 'batch_size': 140, 'epochs': 90, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005795599386667651, 'num_heads': 8, 'heads_p_dropout': 0.39806650103539604}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 64.40%\n",
      "\u001b[32m[I 2023-12-01 12:16:18,832]\u001b[0m Trial 69 finished with value: 0.644 and parameters: {'lr': 0.0005174260499503603, 'hidden_channels': 64, 'hidden_layers': 1, 'p_dropout': 0.5315677011936825, 'batch_size': 140, 'epochs': 90, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005147698341272835, 'num_heads': 8, 'heads_p_dropout': 0.39149822577148535}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 78.00%\n",
      "\u001b[32m[I 2023-12-01 12:16:26,087]\u001b[0m Trial 74 finished with value: 0.78 and parameters: {'lr': 0.0033390350454987746, 'hidden_channels': 32, 'hidden_layers': 0, 'p_dropout': 0.48481304612636267, 'batch_size': 140, 'epochs': 30, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.007491839957251178, 'num_heads': 8, 'heads_p_dropout': 0.533661535066646}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 78.00%\n",
      "\u001b[32m[I 2023-12-01 12:16:29,729]\u001b[0m Trial 70 finished with value: 0.78 and parameters: {'lr': 0.003378595191413496, 'hidden_channels': 32, 'hidden_layers': 1, 'p_dropout': 0.5358591037334113, 'batch_size': 140, 'epochs': 90, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005023723421752864, 'num_heads': 8, 'heads_p_dropout': 0.3856403045626025}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 75.00%\n",
      "\u001b[32m[I 2023-12-01 12:16:32,120]\u001b[0m Trial 73 finished with value: 0.75 and parameters: {'lr': 0.004299164909184055, 'hidden_channels': 32, 'hidden_layers': 0, 'p_dropout': 0.5595498945865433, 'batch_size': 140, 'epochs': 100, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.007456717518121335, 'num_heads': 8, 'heads_p_dropout': 0.5384912332602521}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 75.40%\n",
      "\u001b[32m[I 2023-12-01 12:16:33,128]\u001b[0m Trial 71 finished with value: 0.754 and parameters: {'lr': 0.0034372407756232282, 'hidden_channels': 32, 'hidden_layers': 1, 'p_dropout': 0.4822624725713892, 'batch_size': 140, 'epochs': 90, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.004663725929620731, 'num_heads': 8, 'heads_p_dropout': 0.39664583565103123}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 77.20%\n",
      "\u001b[32m[I 2023-12-01 12:16:44,531]\u001b[0m Trial 72 finished with value: 0.772 and parameters: {'lr': 0.0031456324917483697, 'hidden_channels': 32, 'hidden_layers': 1, 'p_dropout': 0.5611093096858482, 'batch_size': 140, 'epochs': 100, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.004420323130629551, 'num_heads': 8, 'heads_p_dropout': 0.5317449695808959}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 75.80%\n",
      "\u001b[32m[I 2023-12-01 12:17:20,231]\u001b[0m Trial 75 finished with value: 0.758 and parameters: {'lr': 0.002151610145637388, 'hidden_channels': 64, 'hidden_layers': 1, 'p_dropout': 0.5694119233500409, 'batch_size': 140, 'epochs': 70, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.004482156023429378, 'num_heads': 8, 'heads_p_dropout': 0.34020809285466924}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 76.40%\n",
      "\u001b[32m[I 2023-12-01 12:17:27,190]\u001b[0m Trial 76 finished with value: 0.764 and parameters: {'lr': 0.0021004697513604446, 'hidden_channels': 64, 'hidden_layers': 1, 'p_dropout': 0.5586201615001355, 'batch_size': 140, 'epochs': 70, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005563428840670682, 'num_heads': 8, 'heads_p_dropout': 0.3309395612844722}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 75.80%\n",
      "\u001b[32m[I 2023-12-01 12:17:30,770]\u001b[0m Trial 77 finished with value: 0.758 and parameters: {'lr': 0.0022550923113721535, 'hidden_channels': 64, 'hidden_layers': 1, 'p_dropout': 0.5594955116923374, 'batch_size': 140, 'epochs': 70, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005443796620766228, 'num_heads': 8, 'heads_p_dropout': 0.3529335529661014}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 78.60%\n",
      "\u001b[32m[I 2023-12-01 12:17:34,082]\u001b[0m Trial 78 finished with value: 0.786 and parameters: {'lr': 0.0022154642552475847, 'hidden_channels': 64, 'hidden_layers': 1, 'p_dropout': 0.46881229887820425, 'batch_size': 140, 'epochs': 70, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.00570533688582006, 'num_heads': 8, 'heads_p_dropout': 0.34997648529157055}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 77.40%\n",
      "\u001b[32m[I 2023-12-01 12:17:46,754]\u001b[0m Trial 79 finished with value: 0.774 and parameters: {'lr': 0.00231406351932821, 'hidden_channels': 64, 'hidden_layers': 1, 'p_dropout': 0.5251877553696394, 'batch_size': 140, 'epochs': 70, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005547382253747222, 'num_heads': 8, 'heads_p_dropout': 0.34776973436764885}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 77.80%\n",
      "\u001b[32m[I 2023-12-01 12:17:56,922]\u001b[0m Trial 81 finished with value: 0.778 and parameters: {'lr': 0.005617184071878058, 'hidden_channels': 64, 'hidden_layers': 0, 'p_dropout': 0.5251850743292826, 'batch_size': 140, 'epochs': 40, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005757995583771114, 'num_heads': 8, 'heads_p_dropout': 0.41941583283945677}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 76.60%\n",
      "\u001b[32m[I 2023-12-01 12:18:15,994]\u001b[0m Trial 80 finished with value: 0.766 and parameters: {'lr': 0.0050628764635190565, 'hidden_channels': 64, 'hidden_layers': 1, 'p_dropout': 0.4707741855884967, 'batch_size': 140, 'epochs': 40, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005593879579458713, 'num_heads': 8, 'heads_p_dropout': 0.6122679141234237}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 75.80%\n",
      "\u001b[32m[I 2023-12-01 12:18:22,692]\u001b[0m Trial 83 finished with value: 0.758 and parameters: {'lr': 0.005854014261287484, 'hidden_channels': 128, 'hidden_layers': 0, 'p_dropout': 0.46764154129766805, 'batch_size': 140, 'epochs': 40, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.006716875542268929, 'num_heads': 8, 'heads_p_dropout': 0.41643943466139527}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 74.60%\n",
      "\u001b[32m[I 2023-12-01 12:18:35,204]\u001b[0m Trial 82 finished with value: 0.746 and parameters: {'lr': 0.005796709776677008, 'hidden_channels': 256, 'hidden_layers': 0, 'p_dropout': 0.546249775029008, 'batch_size': 140, 'epochs': 40, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0065461606350274, 'num_heads': 8, 'heads_p_dropout': 0.422536650226829}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 77.80%\n",
      "\u001b[32m[I 2023-12-01 12:18:59,997]\u001b[0m Trial 84 finished with value: 0.778 and parameters: {'lr': 0.006384378227638566, 'hidden_channels': 256, 'hidden_layers': 0, 'p_dropout': 0.47178512180395066, 'batch_size': 140, 'epochs': 40, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.006697840819073185, 'num_heads': 8, 'heads_p_dropout': 0.42276402124912255}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 77.00%\n",
      "\u001b[32m[I 2023-12-01 12:20:26,028]\u001b[0m Trial 88 finished with value: 0.77 and parameters: {'lr': 0.0017367957567235594, 'hidden_channels': 64, 'hidden_layers': 1, 'p_dropout': 0.44474563622169283, 'batch_size': 140, 'epochs': 50, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005977599815822938, 'num_heads': 8, 'heads_p_dropout': 0.4577154411345198}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 76.60%\n",
      "\u001b[32m[I 2023-12-01 12:20:39,798]\u001b[0m Trial 89 finished with value: 0.766 and parameters: {'lr': 0.0016366598915233575, 'hidden_channels': 64, 'hidden_layers': 1, 'p_dropout': 0.4469450132932909, 'batch_size': 140, 'epochs': 50, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0060254932524087665, 'num_heads': 8, 'heads_p_dropout': 0.4545658363427461}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 46.80%\n",
      "\u001b[32m[I 2023-12-01 12:21:11,196]\u001b[0m Trial 90 finished with value: 0.468 and parameters: {'lr': 0.0016318918053187753, 'hidden_channels': 64, 'hidden_layers': 1, 'p_dropout': 0.5139892881444001, 'batch_size': 140, 'epochs': 20, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0052614868830169, 'num_heads': 8, 'heads_p_dropout': 0.30367945226160026}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 65.00%\n",
      "\u001b[32m[I 2023-12-01 12:21:27,376]\u001b[0m Trial 92 finished with value: 0.65 and parameters: {'lr': 0.00407805784628723, 'hidden_channels': 128, 'hidden_layers': 0, 'p_dropout': 0.49575961527735624, 'batch_size': 140, 'epochs': 10, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.006394115488668492, 'num_heads': 8, 'heads_p_dropout': 0.3686095259965662}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 76.40%\n",
      "\u001b[32m[I 2023-12-01 12:21:46,152]\u001b[0m Trial 85 finished with value: 0.764 and parameters: {'lr': 0.0016508593143101688, 'hidden_channels': 256, 'hidden_layers': 1, 'p_dropout': 0.46510665017554265, 'batch_size': 140, 'epochs': 50, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.006620829120669743, 'num_heads': 8, 'heads_p_dropout': 0.3083770882310144}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 48.20%\n",
      "\u001b[32m[I 2023-12-01 12:21:55,792]\u001b[0m Trial 91 finished with value: 0.482 and parameters: {'lr': 0.0027883795883242176, 'hidden_channels': 128, 'hidden_layers': 2, 'p_dropout': 0.5121549494726856, 'batch_size': 140, 'epochs': 20, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.006427132750081086, 'num_heads': 8, 'heads_p_dropout': 0.3644434804348215}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 74.60%\n",
      "\u001b[32m[I 2023-12-01 12:22:00,415]\u001b[0m Trial 86 finished with value: 0.746 and parameters: {'lr': 0.0016039058095125532, 'hidden_channels': 256, 'hidden_layers': 1, 'p_dropout': 0.5102791918486367, 'batch_size': 140, 'epochs': 50, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.0065527466087945, 'num_heads': 8, 'heads_p_dropout': 0.3139536716553981}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 76.00%\n",
      "\u001b[32m[I 2023-12-01 12:22:06,785]\u001b[0m Trial 87 finished with value: 0.76 and parameters: {'lr': 0.001781081443860884, 'hidden_channels': 256, 'hidden_layers': 1, 'p_dropout': 0.4435576740957322, 'batch_size': 140, 'epochs': 50, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.006133124233805371, 'num_heads': 8, 'heads_p_dropout': 0.30600812639090247}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 76.40%\n",
      "\u001b[32m[I 2023-12-01 12:22:31,606]\u001b[0m Trial 95 finished with value: 0.764 and parameters: {'lr': 0.0014219239055352814, 'hidden_channels': 32, 'hidden_layers': 1, 'p_dropout': 0.494471940983598, 'batch_size': 140, 'epochs': 60, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005798040931020973, 'num_heads': 8, 'heads_p_dropout': 0.4369060544667774}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 77.60%\n",
      "\u001b[32m[I 2023-12-01 12:22:33,009]\u001b[0m Trial 96 finished with value: 0.776 and parameters: {'lr': 0.0029642909692842103, 'hidden_channels': 32, 'hidden_layers': 1, 'p_dropout': 0.4927658268462593, 'batch_size': 140, 'epochs': 60, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005827878970070445, 'num_heads': 8, 'heads_p_dropout': 0.4342007316790981}. Best is trial 61 with value: 0.81.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramme\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adamax.Adamax'> which is of type type.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 78.40%\n",
      "\u001b[32m[I 2023-12-01 12:22:37,520]\u001b[0m Trial 94 finished with value: 0.784 and parameters: {'lr': 0.0027540533103146037, 'hidden_channels': 64, 'hidden_layers': 0, 'p_dropout': 0.47595511829559634, 'batch_size': 140, 'epochs': 110, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005319784351739676, 'num_heads': 8, 'heads_p_dropout': 0.6834849604328248}. Best is trial 61 with value: 0.81.\u001b[0m\n",
      "Validation Accuracy: 53.00%\n",
      "\u001b[32m[I 2023-12-01 12:22:38,327]\u001b[0m Trial 97 finished with value: 0.53 and parameters: {'lr': 0.001123810010552763, 'hidden_channels': 32, 'hidden_layers': 1, 'p_dropout': 0.4968870028501719, 'batch_size': 140, 'epochs': 60, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.007238321857802193, 'num_heads': 8, 'heads_p_dropout': 0.4336462926658107}. Best is trial 61 with value: 0.81.\u001b[0m\n",
      "Validation Accuracy: 77.40%\n",
      "\u001b[32m[I 2023-12-01 12:22:45,366]\u001b[0m Trial 98 finished with value: 0.774 and parameters: {'lr': 0.0011480595690272078, 'hidden_channels': 32, 'hidden_layers': 0, 'p_dropout': 0.4760732714198087, 'batch_size': 140, 'epochs': 60, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005295638188281523, 'num_heads': 8, 'heads_p_dropout': 0.43731031515110735}. Best is trial 61 with value: 0.81.\u001b[0m\n",
      "Validation Accuracy: 78.20%\n",
      "\u001b[32m[I 2023-12-01 12:22:54,426]\u001b[0m Trial 99 finished with value: 0.782 and parameters: {'lr': 0.0010514239723283844, 'hidden_channels': 32, 'hidden_layers': 0, 'p_dropout': 0.5198572502450045, 'batch_size': 140, 'epochs': 110, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005370384432304594, 'num_heads': 8, 'heads_p_dropout': 0.41056622443666246}. Best is trial 61 with value: 0.81.\u001b[0m\n",
      "Validation Accuracy: 74.00%\n",
      "\u001b[32m[I 2023-12-01 12:23:06,804]\u001b[0m Trial 93 finished with value: 0.74 and parameters: {'lr': 0.003003592352911351, 'hidden_channels': 64, 'hidden_layers': 2, 'p_dropout': 0.4770941838676899, 'batch_size': 140, 'epochs': 110, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.00719865739325192, 'num_heads': 8, 'heads_p_dropout': 0.276038247630024}. Best is trial 61 with value: 0.81.\u001b[0m\n",
      "FrozenTrial(number=61, state=TrialState.COMPLETE, values=[0.81], datetime_start=datetime.datetime(2023, 12, 1, 12, 14, 36, 995616), datetime_complete=datetime.datetime(2023, 12, 1, 12, 15, 22, 108286), params={'lr': 0.0013191168503116166, 'hidden_channels': 64, 'hidden_layers': 1, 'p_dropout': 0.5048414017214051, 'batch_size': 140, 'epochs': 60, 'optimizer': <class 'torch.optim.adamax.Adamax'>, 'weight_decay': 0.005908460006339683, 'num_heads': 8, 'heads_p_dropout': 0.4423211437386582}, user_attrs={}, system_attrs={}, intermediate_values={1: 1.9465137720108032, 2: 1.9413384199142456, 3: 1.934877872467041, 4: 1.9314810037612915, 5: 1.9244914054870605, 6: 1.919739007949829, 7: 1.9134184122085571, 8: 1.9103643894195557, 9: 1.9036946296691895, 10: 1.8978710174560547, 11: 1.888895034790039, 12: 1.882323145866394, 13: 1.8727598190307617, 14: 1.8638240098953247, 15: 1.8519049882888794, 16: 1.8383228778839111, 17: 1.8221893310546875, 18: 1.8119678497314453, 19: 1.7888339757919312, 20: 1.7735544443130493, 21: 1.7605690956115723, 22: 1.7321791648864746, 23: 1.7203843593597412, 24: 1.694782018661499, 25: 1.6750781536102295, 26: 1.6496531963348389, 27: 1.6349421739578247, 28: 1.608742117881775, 29: 1.5900403261184692, 30: 1.5687665939331055, 31: 1.5501928329467773, 32: 1.533866286277771, 33: 1.5148025751113892, 34: 1.4986317157745361, 35: 1.4809255599975586, 36: 1.470541000366211, 37: 1.4532920122146606, 38: 1.4445292949676514, 39: 1.4318205118179321, 40: 1.4232546091079712, 41: 1.4133591651916504, 42: 1.4061282873153687, 43: 1.391248106956482, 44: 1.3953826427459717, 45: 1.379309058189392, 46: 1.3775861263275146, 47: 1.366969347000122, 48: 1.3594646453857422, 49: 1.352010726928711, 50: 1.3527023792266846, 51: 1.3444267511367798, 52: 1.3435497283935547, 53: 1.3285155296325684, 54: 1.3290765285491943, 55: 1.3213540315628052, 56: 1.3223025798797607, 57: 1.3199807405471802, 58: 1.314035415649414, 59: 1.3132990598678589, 60: 1.3053030967712402}, distributions={'lr': FloatDistribution(high=0.01, log=True, low=1e-05, step=None), 'hidden_channels': CategoricalDistribution(choices=(8, 16, 32, 64, 128, 256)), 'hidden_layers': CategoricalDistribution(choices=(0, 1, 2)), 'p_dropout': FloatDistribution(high=0.7, log=False, low=0.4, step=None), 'batch_size': CategoricalDistribution(choices=(140,)), 'epochs': CategoricalDistribution(choices=(10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120)), 'optimizer': CategoricalDistribution(choices=(<class 'torch.optim.adamax.Adamax'>,)), 'weight_decay': FloatDistribution(high=0.01, log=False, low=1e-05, step=None), 'num_heads': CategoricalDistribution(choices=(4, 8, 16)), 'heads_p_dropout': FloatDistribution(high=0.7, log=False, low=0.1, step=None)}, trial_id=61, value=None)\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.pruners import SuccessiveHalvingPruner, NopPruner\n",
    "from torch.optim import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, NAdam\n",
    "import numpy as np\n",
    "\n",
    "n_trails = 100\n",
    "n_jobs = 5 # Number of parallel jobs\n",
    "\n",
    "def objective(trial):\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    hidden_channels = trial.suggest_categorical('hidden_channels', [8,16,32,64,128,256]) #try [16,32,64,128,256]\n",
    "    size_gat = trial.suggest_categorical('hidden_layers', [0,1,2])\n",
    "    p_dropout = trial.suggest_float('p_dropout', 0.4, 0.7)\n",
    "    batch_size=trial.suggest_categorical('batch_size', [140]) # entire training set / batch training\n",
    "    epochs = trial.suggest_categorical('epochs', np.arange(10,130,10).tolist())\n",
    "    #optimizer = trial.suggest_categorical('optimizer', [SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, NAdam])\n",
    "    optimizer = trial.suggest_categorical('optimizer', [Adamax])\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-2)\n",
    "    num_heads = trial.suggest_categorical('num_heads', [4,8,16])\n",
    "    heads_p_dropout = trial.suggest_float('heads_p_dropout', 0.1, 0.7)\n",
    "    \n",
    "    data = dataset[0]\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    #(self, num_features, num_classes, hidden_channels, dropout, num_heads, size_gat)\n",
    "    model = GAT(num_features=data.num_features, num_classes=dataset.num_classes, hidden_channels=hidden_channels, \n",
    "                num_heads=num_heads, heads_p_dropout=heads_p_dropout,size_gat=size_gat, p_dropout=p_dropout)\n",
    "    optimizer = optimizer(model.parameters(), lr=lr, weight_decay=weight_decay)#, momentum=0.9) #for RMSprop\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        for data in loader:\n",
    "            criterion=nn.CrossEntropyLoss()\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data.x, data.edge_index)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            trial.report(loss, epoch)\n",
    "\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    # Validate model\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)  # Predicted probabilities\n",
    "    probas = torch.nn.functional.softmax(out, dim=1)  # Convert logits to probabilities\n",
    "    pred = probas.argmax(dim=1)\n",
    "\n",
    "    # Only consider validation data\n",
    "    true_labels = data.y[data.val_mask].cpu().numpy()\n",
    "    predicted_labels = pred[data.val_mask].cpu().numpy()\n",
    "\n",
    "    # Recall\n",
    "    recall = recall_score(true_labels, predicted_labels, average='macro')  # Using macro average\n",
    "\n",
    "    # Acuracy\n",
    "    correct = pred[data.val_mask].eq(data.y[data.val_mask]).sum().item()\n",
    "    acc = correct / data.val_mask.sum().item()\n",
    "    print(f'Validation Accuracy: {acc * 100:.2f}%')\n",
    "    \n",
    "    # F1 score\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "    #append the metrics to a csv file, and include the columns: avg_auc, recall, acc, f1\n",
    "    with open('GAT_cora_test_results04.csv', 'a') as f:\n",
    "        optimizer_name=optimizer.__class__.__name__\n",
    "        f.write(f'{batch_size}, {hidden_channels}, {num_heads},{size_gat},{heads_p_dropout},{lr}, {weight_decay}, {epochs}, {p_dropout}, {optimizer_name},{recall},{acc},{f1}\\n')\n",
    "    \n",
    "    return acc\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=NopPruner())\n",
    "#study = optuna.create_study(direction=\"minimize\", pruner=SuccessiveHalvingPruner(min_resource=1, reduction_factor=4, min_early_stopping_rate=0))\n",
    "study.optimize(objective, n_trials=n_trails, timeout=6000, n_jobs=n_jobs,show_progress_bar = True)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e4963f6-8330-4941-98fd-08cbe14335a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.00010436594091179323, 'hidden_channels': 16, 'hidden_layers': 0, 'p_dropout': 0.4465534667574045, 'batch_size': 128, 'epochs': 200, 'optimizer': <class 'torch.optim.adam.Adam'>, 'weight_decay': 5.40503466421723e-05, 'num_heads': 8}\n"
     ]
    }
   ],
   "source": [
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd697959-4bdb-4a59-ad15-84e116aaab64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>hidden_channels</th>\n",
       "      <th>num_heads</th>\n",
       "      <th>size_gat</th>\n",
       "      <th>heads_p_dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>epochs</th>\n",
       "      <th>p_dropout</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>recall</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>140</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.442321</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.005908</td>\n",
       "      <td>60</td>\n",
       "      <td>0.504841</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>0.820408</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.796731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>140</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.699724</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>60</td>\n",
       "      <td>0.549744</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>0.823069</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.797650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>140</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.620153</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>20</td>\n",
       "      <td>0.672601</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.809805</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.790469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>140</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.686240</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>20</td>\n",
       "      <td>0.532862</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.791978</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.785846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>140</td>\n",
       "      <td>256</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.656421</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.009433</td>\n",
       "      <td>90</td>\n",
       "      <td>0.450874</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>0.815967</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.785716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>140</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.317787</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>60</td>\n",
       "      <td>0.493932</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.788267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>140</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.278171</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>110</td>\n",
       "      <td>0.595328</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>0.818523</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.787752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>140</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.425403</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>20</td>\n",
       "      <td>0.584113</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>0.814421</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.783548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>140</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407551</td>\n",
       "      <td>0.009288</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>90</td>\n",
       "      <td>0.599208</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.805100</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.780690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>140</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.171058</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>120</td>\n",
       "      <td>0.551317</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.811165</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.780957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     batch_size  hidden_channels  num_heads  size_gat  heads_p_dropout  \\\n",
       "264         140               64          8         1         0.442321   \n",
       "178         140              128          8         1         0.699724   \n",
       "86          140               64          8         0         0.620153   \n",
       "142         140               32          8         1         0.686240   \n",
       "192         140              256          8         1         0.656421   \n",
       "19          140               16         16         1         0.317787   \n",
       "190         140                8          8         2         0.278171   \n",
       "201         140               32          8         0         0.425403   \n",
       "67          140                8          4         0         0.407551   \n",
       "39          140               16         16         1         0.171058   \n",
       "\n",
       "           lr  weight_decay  epochs  p_dropout optimizer    recall    acc  \\\n",
       "264  0.001319      0.005908      60   0.504841    Adamax  0.820408  0.810   \n",
       "178  0.004374      0.007152      60   0.549744    Adamax  0.823069  0.808   \n",
       "86   0.002870      0.002089      20   0.672601      Adam  0.809805  0.802   \n",
       "142  0.001427      0.000351      20   0.532862      Adam  0.791978  0.798   \n",
       "192  0.000918      0.009433      90   0.450874    Adamax  0.815967  0.798   \n",
       "19   0.000464      0.004264      60   0.493932   RMSprop  0.813187  0.796   \n",
       "190  0.003691      0.002000     110   0.595328    Adamax  0.818523  0.794   \n",
       "201  0.004503      0.006155      20   0.584113    Adamax  0.814421  0.794   \n",
       "67   0.009288      0.001757      90   0.599208      Adam  0.805100  0.792   \n",
       "39   0.000906      0.005002     120   0.551317   RMSprop  0.811165  0.792   \n",
       "\n",
       "           f1  \n",
       "264  0.796731  \n",
       "178  0.797650  \n",
       "86   0.790469  \n",
       "142  0.785846  \n",
       "192  0.785716  \n",
       "19   0.788267  \n",
       "190  0.787752  \n",
       "201  0.783548  \n",
       "67   0.780690  \n",
       "39   0.780957  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "results_df = pd.read_csv('GAT_cora_test_results04.csv', header=None)\n",
    "results_df.columns = ['batch_size', 'hidden_channels', 'num_heads','size_gat','heads_p_dropout', 'lr', 'weight_decay', 'epochs', 'p_dropout', 'optimizer', 'recall', 'acc', 'f1']\n",
    "\n",
    "results_df.sort_values('acc', ascending=False).iloc[:10]\n",
    "#results_df.loc[results_df['optimizer']]\n",
    "#results_df[results_df.optimizer.str.contains('Adam')].sort_values('acc', ascending=False).iloc[:5]\n",
    "\n",
    "#Model with intermediate dropouts\n",
    "# 128 16 16\t0 0.692889\t0.000491\t0.002541\t100\t0.597672\tAdam\t0.826481\t0.810\t0.795890 | recall 0.811940 acc 0.791800 f1 0.790024\n",
    "# 256 8\t8\t1 0.342939\t0.003539\t0.006355\t100\t0.615685\tAdam\t0.818477\t0.798\t0.788357 | recall 0.799963 acc 0.784200 f1 0.778919\n",
    "# 16 8 8    1 0.214470\t0.001952\t0.005183\t100\t0.561916\tAdam\t0.821532\t0.796\t0.786771 | recall 0.806776 acc 0.793900 f1 0.787959\n",
    "# 256 8\t8\t0 0.693739\t0.001282\t0.005451\t100\t0.695004\tAdam\t0.808504\t0.792\t0.777007 | recall 0.821401 acc 0.802500 f1 0.798981\n",
    "\n",
    "# 16 8\t8\t1 0.365570\t0.003452\t0.005054\t100\t0.515095\tRMSprop\t0.811762\t0.798\t0.784681 | recall 0.80490 acc 0.78300 f1 0.78022\n",
    "# 16 16\t8\t1 0.361727\t0.000210\t0.003056\t100\t0.497582\tRMSprop\t0.819189\t0.792\t0.790542 | recall 0.807747 acc 0.787900 f1 0.785956\n",
    "\n",
    "# 16 16\t16\t1 0.298358\t0.000509\t0.006146\t200\t0.520403\tAdamax\t0.833137\t0.812\t0.806787 | recall 0.810468 acc 0.791000 f1 0.788410\n",
    "# 16 32\t16\t1 0.221265\t0.000761\t0.005568\t200\t0.525549\tAdamax\t0.807103\t0.788\t0.775959 | recall 0.798144 acc 0.782200 f1 0.779102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e29821b-39c4-41ef-8ce2-3005360cd777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file was deleted\n"
     ]
    }
   ],
   "source": [
    "# DELETE FILE that stores the HYPERPARAMETERS\n",
    "# import os\n",
    "# if os.path.exists(\"GAT_cora_test_results04.csv\"):\n",
    "#     os.remove(\"GAT_cora_test_results04.csv\")\n",
    "#     print(\"The file was deleted\")\n",
    "# else:\n",
    "#   print(\"The file does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da57c8f8-de33-4f77-964b-b0caf0b466c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hyperparameters from dataframe\n",
    "slc_row=2\n",
    "batch_size=int(results_df.sort_values('acc', ascending=False).iloc[slc_row]['batch_size'])\n",
    "hidden_channels = int(results_df.sort_values('acc', ascending=False).iloc[slc_row]['hidden_channels'])\n",
    "size_gat = results_df.sort_values('acc', ascending=False).iloc[slc_row]['size_gat']\n",
    "lr = results_df.sort_values('acc', ascending=False).iloc[slc_row]['lr']\n",
    "weight_decay = results_df.sort_values('acc', ascending=False).iloc[slc_row]['weight_decay']\n",
    "epochs = results_df.sort_values('acc', ascending=False).iloc[slc_row]['epochs']\n",
    "p_dropout = results_df.sort_values('acc', ascending=False).iloc[slc_row]['p_dropout']\n",
    "num_heads = int(results_df.sort_values('acc', ascending=False).iloc[slc_row]['num_heads'])\n",
    "heads_p_dropout=int(results_df.sort_values('acc', ascending=False).iloc[slc_row]['heads_p_dropout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "55e93ef0-8196-45e1-8469-c7ef3ae2bd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0006522990207284269,\n",
       " 'hidden_channels': 8,\n",
       " 'hidden_layers': 1,\n",
       " 'p_dropout': 0.6760540197652862,\n",
       " 'batch_size': 128,\n",
       " 'epochs': 200,\n",
       " 'optimizer': torch.optim.rmsprop.RMSprop,\n",
       " 'weight_decay': 0.004112674572557716,\n",
       " 'num_heads': 8}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "945d38e8-25c9-4ee8-af94-3899373eb30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hyperparameters from dataframe - select specific OPTIMIZER\n",
    "slc_row=0\n",
    "optim='RMSprop'\n",
    "batch_size=int(results_df[results_df.optimizer.str.contains(optim)].sort_values('acc', ascending=False).iloc[slc_row]['batch_size'])\n",
    "hidden_channels = int(results_df[results_df.optimizer.str.contains(optim)].sort_values('acc', ascending=False).iloc[slc_row]['hidden_channels'])\n",
    "size_gat = results_df[results_df.optimizer.str.contains(optim)].sort_values('acc', ascending=False).iloc[slc_row]['size_gat']\n",
    "lr = results_df[results_df.optimizer.str.contains(optim)].sort_values('acc', ascending=False).iloc[slc_row]['lr']\n",
    "weight_decay = results_df[results_df.optimizer.str.contains(optim)].sort_values('acc', ascending=False).iloc[slc_row]['weight_decay']\n",
    "epochs = results_df[results_df.optimizer.str.contains(optim)].sort_values('acc', ascending=False).iloc[slc_row]['epochs']\n",
    "p_dropout = results_df[results_df.optimizer.str.contains(optim)].sort_values('acc', ascending=False).iloc[slc_row]['p_dropout']\n",
    "num_heads = int(results_df[results_df.optimizer.str.contains(optim)].sort_values('acc', ascending=False).iloc[slc_row]['num_heads'])\n",
    "heads_p_dropout = int(results_df[results_df.optimizer.str.contains(optim)].sort_values('acc', ascending=False).iloc[slc_row]['heads_p_dropout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d262022-7594-4246-a2da-f7fff4a5b005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0028700863669291"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0017e39f-35cf-48f2-9650-967ed8ffa645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters from study\n",
    "batch_size = study.best_params['batch_size']\n",
    "hidden_channels = study.best_params['hidden_channels']\n",
    "size_gat = study.best_params['hidden_layers']\n",
    "lr = study.best_params['lr']\n",
    "weight_decay = study.best_params['weight_decay']\n",
    "epochs = study.best_params['epochs']\n",
    "p_dropout = study.best_params['dropout']\n",
    "num_heads = study.best_params['num_heads']\n",
    "optimizer = Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ba2e1f99-8420-4d2b-9d90-e15ffa0e8495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set hyperparameters\n",
    "# Best model so far\n",
    "batch_size = 32\n",
    "hidden_channels = 8\n",
    "size_gat = 0\n",
    "lr = 0.003663\t\n",
    "weight_decay = 0.005504\n",
    "epochs = 100\n",
    "p_dropout = 0.660999\n",
    "num_heads = 16\n",
    "optimizer = RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab3552a3-b77b-4480-84b5-383352d8728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, NAdam\n",
    "#optimizer = Adam\n",
    "def train(model,optimizer,data,epoch):\n",
    "    criterion=nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)  # Predicted probabilities\n",
    "    probas = torch.nn.functional.softmax(out, dim=1)  # Convert logits to probabilities\n",
    "    pred = probas.argmax(dim=1)\n",
    "\n",
    "    # Test data\n",
    "    true_labels = data.y[data.test_mask].cpu().numpy()\n",
    "    predicted_labels = pred[data.test_mask].cpu().numpy()\n",
    "\n",
    "    # Recall\n",
    "    recall = recall_score(true_labels, predicted_labels, average='macro')  # Using macro average\n",
    "    #print(f'Test Recall: {recall:.4f}')\n",
    "\n",
    "    # Acuracy\n",
    "    correct = pred[data.test_mask].eq(data.y[data.test_mask]).sum().item()\n",
    "    acc = correct / data.test_mask.sum().item()\n",
    "    #print(f'Test Accuracy: {acc * 100:.2f}%')\n",
    "\n",
    "    # F1 score\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "    #print(f'Test F1 score: {f1:.4f}')\n",
    "\n",
    "    #append the metrics to a csv file, and include the columns: avg_auc, recall, acc, f1\n",
    "    with open('GAT_cora_best_model_metrics04.csv', 'a') as f:\n",
    "        f.write(f'{recall},{acc},{f1}\\n')\n",
    "\n",
    "def test_GAT(dataset,batch_size,hidden_channels,p_dropout,num_heads,heads_p_dropout,size_gat,optimizer,lr,weight_decay,epochs):\n",
    "#(self, num_features, num_classes, hidden_channels, dropout, num_heads, size_gat)\n",
    "    data = dataset[0]\n",
    "    loader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "    # Initialize the model and optimizer\n",
    "    model = GAT(num_features=data.num_features, num_classes=dataset.num_classes, hidden_channels=hidden_channels, p_dropout=p_dropout, \n",
    "                heads_p_dropout=heads_p_dropout,num_heads=num_heads, size_gat=size_gat)\n",
    "    optimizer = optimizer(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=0.9) #for RMSprop\n",
    "    # Training loop\n",
    "    for epoch in range(1, epochs+1):\n",
    "        for data in loader:\n",
    "            train(model,optimizer,data,epoch)\n",
    "    \n",
    "    test(model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c615fe4-4d25-4178-a8d9-8c19e66f7044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file was deleted\n"
     ]
    }
   ],
   "source": [
    "# DELETE FILE that stores the METRICS\n",
    "import os\n",
    "if os.path.exists(\"GAT_cora_best_model_metrics04.csv\"):\n",
    "    os.remove(\"GAT_cora_best_model_metrics04.csv\")\n",
    "    print(\"The file was deleted\")\n",
    "else:\n",
    "  print(\"The file does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "588a0c37-de60-4585-843b-25198b39558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "times=[]\n",
    "optimizer=RMSprop\n",
    "momentum = 0.9\n",
    "for i in range (0,10):\n",
    "    st = time.time()\n",
    "    test_GAT(dataset,batch_size,hidden_channels,p_dropout,num_heads,heads_p_dropout,size_gat,optimizer,lr,weight_decay,epochs)\n",
    "    et = time.time()\n",
    "    elapsed_time = et - st\n",
    "    #print('Execution time:', elapsed_time, 'seconds')\n",
    "    times.append(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f164122f-e105-4e3e-bcc0-c83fca78daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "best_model_df = pd.read_csv('GAT_cora_best_model_metrics04.csv', header=None)\n",
    "best_model_df.columns = ['recall', 'acc', 'f1']\n",
    "best_model_df['train_and_test_time']=times\n",
    "avg_df=best_model_df[['recall', 'acc', 'f1','train_and_test_time']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04e3dde3-9c9c-44fa-940d-268e4e97b2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recall                 0.798520\n",
       "acc                    0.780400\n",
       "f1                     0.776577\n",
       "train_and_test_time    6.936770\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_df #0.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ee21972-9f5a-4905-a0d0-0cbd32c41c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009640193635676282\n",
      "train_and_test_time    0.115613\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#According to Schur et al. in Pitfalls of Graph Neural Network Evaluation, the GAT is slightly better than\n",
    "#the GCN (82.8%  0.6% versus 81.9%  0.8%) on Cora and CiteSeer (71.0  0.6% versus 69.5% \n",
    "#0.9%).\n",
    "print(best_model_df['acc'].std())\n",
    "print(best_model_df[['train_and_test_time']].mean() / epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb457285-c0dd-4016-9c42-1e75d37eb4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gat = GAT(data.num_features, dataset.num_classes, hidden_channels, num_heads,heads_p_dropout,size_gat,p_dropout)\n",
    "#num_features, num_classes, hidden_channels, num_heads, heads_p_dropout,size_gat, p_dropout):\n",
    "optimizer=Adam\n",
    "\n",
    "data = dataset[0]\n",
    "loader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "# Initialize the model and optimizer\n",
    "optimizer = optimizer(gat.parameters(), lr=lr, weight_decay=weight_decay)#,momentum=0.9) #for RMSprop)\n",
    "# Training loop\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    for data in loader:\n",
    "        train(gat,optimizer,data,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f251236-cdbb-4a4c-a6c4-80109d06f3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHqCAYAAADVi/1VAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACfsElEQVR4nOzdeVxO6f8/8Nfdvof2aBOyZyeRrNn3GrswsmSIYTD2fexm4oMwaSj7MjFjL4axlywjCSWkkqWylNT1+8Ov83W727VYXs/H435wX+e6r/M+59zru+u8j0wIIUBERERERERERFSClEo7ACIiIiIiIiIi+vYwKUVERERERERERCWOSSkiIiIiIiIiIipxTEoREREREREREVGJY1KKiIiIiIiIiIhKHJNSRERERERERERU4piUIiIiIiIiIiKiEsekFBERERERERERlTgmpYiIiIiIiIiIqMQxKUVE9I2Lj49H7969YWBgAJlMhlWrVpV2SF+M6OhoyGQybN68ucCPPXnyJGQyGU6ePFnkcQGAs7MznJ2d8923Zs2axRJHfllbW8Pd3b1UY/gcuLu7w9raukjHLMhzgehz8zm8PxWH2bNnQyaTlXYYRESljkkpIvqs/e9//4NMJkPjxo1LO5Sv1vjx43HkyBFMnToVW7ZsQfv27XPtn5aWBm9vbzRr1gxly5aFmpoazM3N0bVrV2zbtg0ZGRnZPi48PBwymQwaGhp48eKF1O7u7g6ZTJbnLbeERdaXeyUlJTx48EBheXJyMjQ1NSGTyTBmzJh87ZevTWxsLGbPno2wsLBiW0dGRgbMzc0hk8lw6NChYltPSTp48CDat28PAwMDaGhooEqVKpg4cSKePn1a6DFL4ljQe8nJyZgzZw7s7e2ho6MDTU1N1KxZE5MnT0ZsbGxphwfgfUI2P++BhUl+Z2fhwoXYv39/vvs/efIE48aNQ9WqVaGpqQljY2M0atQIkydPxsuXLwu8/rNnz2L27NlynwOfg6z9vHz5coVlmzdvhkwmw+XLl0shsvzJijHrpqGhAXNzc7i4uOC3335DSkpKaYdIRJQtldIOgIgoN/7+/rC2tsbFixdx584dVKpUqbRD+uoEBQWhW7dumDhxYp59nzx5gg4dOiAkJAQuLi6YPn06ypUrh7i4OBw/fhz9+vXDnTt3MGPGDIXHbt26Faampnj+/Dl2796N77//HgAwYsQItGnTRuoXFRWFmTNnwsPDA82bN5fabW1t84xPXV0d27Ztw08//STXvnfv3jwf+7U5evSo3P3Y2FjMmTMH1tbWqFOnTrGsMygoCI8fP4a1tTX8/f3RoUOHYllPSZk4cSKWL18Oe3t7TJ48GeXKlUNoaChWr16N7du348SJE7CzsyvwuLkdiw0bNiAzM7OItuC9j58L34p79+6hTZs2iImJgaurKzw8PKCmpoZr165h06ZN2LdvH27fvl3aYWLVqlVyyZ2///4b27Ztw8qVK2FoaCi1N23atEjWt3DhQvTu3Rvdu3fPs++zZ8/QoEEDJCcnY+jQoahatSqePn2Ka9euYe3atRg1ahR0dHQKtP6zZ89izpw5cHd3R5kyZQq3EcVo6dKlGDVqFLS0tEo7lEKZO3cubGxskJ6ejri4OJw8eRJeXl5YsWIFAgMDUbt27dIOkYhIDpNSRPTZioqKwtmzZ7F3716MGDEC/v7+mDVrVmmHla1Xr15BW1u7tMMolISEhHz/MBg4cCCuXLmCPXv2oGfPnnLLpk6disuXLyMiIkLhcUIIBAQEoF+/foiKioK/v7+UlHJwcICDg4PU9/Lly5g5cyYcHBwwYMCAAm1Lx44ds01KBQQEoFOnTtizZ0+BxvuSqamplfg6t27dinr16mHw4MH4+eefv+jXxbZt27B8+XJ899138Pf3h7KysrTM3d0dLVu2hKurK0JDQ6GiUnRfp1RVVYtsrCwl/VxITU2FmpoalJRKb0L+u3fv0LNnT8THx+PkyZNo1qyZ3PIFCxZg8eLFRbKuT32ef5wciouLw7Zt29C9e/ciP5WzoDZt2oSYmBj8+++/Ckmx5OTkUnmfKU516tRBWFgY1q1bhwkTJpR2OIXSoUMHNGjQQLo/depUBAUFoXPnzujatSvCw8OhqalZYvEIIZCamlqi6ySiLwtP3yOiz5a/vz/Kli2LTp06oXfv3vD398+234sXLzB+/HhYW1tDXV0dFSpUwKBBg5CYmCj1SU1NxezZs1GlShVoaGjAzMwMPXv2xN27dwHkXN8nu5pB7u7u0NHRwd27d9GxY0fo6uqif//+AIDTp0/D1dUVlpaWUFdXh4WFBcaPH483b94oxH3r1i24ubnByMgImpqasLOzw7Rp0wAAwcHBkMlk2Ldvn8LjAgICIJPJcO7cuVz337179+Dq6opy5cpBS0sLTZo0wV9//SUtz5rqL4TAmjVrpCn/OTl37hyOHDkCDw8PhYRUlgYNGkj74kP//vsvoqOj0adPH/Tp0wf//PMPHj58mGv8hdGvXz+EhYXh1q1bUltcXByCgoLQr1+/bB+TkJCAYcOGwcTEBBoaGrC3t4efn59CvxcvXsDd3R36+vooU6YMBg8enOPpJ7du3ULv3r1Rrlw5aGhooEGDBggMDCzw9ly7dg0ymUzusSEhIZDJZKhXr55c3w4dOsid5vphHaGTJ0+iYcOGAIAhQ4bkeDrQzZs30bJlS2hpaaF8+fJYsmRJvmN98+YN9u3bhz59+sDNzQ1v3rzBn3/+qdBPCIH58+ejQoUK0NLSQsuWLfHff/8p9Hv27BkmTpyIWrVqQUdHB3p6eujQoQOuXr0q1y/rtbtz507MmTMH5cuXh66uLnr37o2kpCSkpaXBy8sLxsbG0NHRwZAhQ5CWlpbn9syZMwdly5aFj4+PXEIKgHTq0vXr17F7926pPav2TUhICJo2bQpNTU3Y2Nhg3bp1cvHmdiw+rimV9R60bNkyrFmzBhUrVoSWlhbatWuHBw8eQAiBefPmoUKFCtDU1ES3bt3w7NkzuXg/rimV2+liH74HPnr0CEOHDoWJiQnU1dVRo0YN/P7779nu/+3bt2P69OkoX748tLS0kJycnOO+ffXqFX788UdYWFhAXV0ddnZ2WLZsGYQQcv2yTrfdv38/atasKcVw+PDhHMfOsmfPHly9ehXTpk1TSEgBgJ6eHhYsWCDXtmvXLtSvXx+ampowNDTEgAED8OjRI7k+RfX+Xxhbt26V4itXrhz69OmjcLpyZGQkevXqBVNTU2hoaKBChQro06cPkpKSALzfp69evYKfn1++To2+e/culJWV0aRJE4Vlenp60NDQkGu7cOEC2rdvD319fWhpaaFFixb4999/peWzZ8/GpEmTAAA2NjZSDNHR0Xluf26vq5cvX0JbWxvjxo1TeNzDhw+hrKyMRYsW5bkOR0dHtGrVCkuWLMnXcQsKCkLz5s2hra2NMmXKoFu3bggPD1fod+bMGTRs2BAaGhqwtbXF+vXrcxwzP8e5oFq1aoUZM2bg/v372Lp1q9yy/H5eXbt2DS1atICmpiYqVKiA+fPnw9fXV+H4WVtbo3Pnzjhy5AgaNGgATU1NaXtfvHgBLy8v6bVfqVIlLF68WGF2aGZmJlatWoUaNWpAQ0MDJiYmGDFiBJ4/f/5J+4GIPk+cKUVEny1/f3/07NkTampq6Nu3L9auXYtLly5JP+iA919EmzdvjvDwcAwdOhT16tVDYmIiAgMD8fDhQxgaGiIjIwOdO3fGiRMn0KdPH4wbNw4pKSk4duwYbty4ka/Twj727t07uLi4oFmzZli2bJk0zX/Xrl14/fo1Ro0aBQMDA1y8eBHe3t54+PAhdu3aJT3+2rVraN68OVRVVeHh4QFra2vcvXsXBw4cwIIFC+Ds7AwLCwv4+/ujR48eCvvF1tZWbnbRx+Lj49G0aVO8fv0aY8eOhYGBAfz8/NC1a1fs3r0bPXr0gJOTE7Zs2YKBAweibdu2GDRoUK7bfODAAQAo8OylD2Nu2LAhatasCS0tLWzbtk36cVJUnJycUKFCBQQEBGDu3LkAgB07dkBHRwedOnVS6P/mzRs4Ozvjzp07GDNmDGxsbLBr1y64u7vjxYsX0g8cIQS6deuGM2fOYOTIkahWrRr27duHwYMHK4z533//wdHREeXLl8eUKVOgra2NnTt3onv37tizZ4/C8cxNzZo1UaZMGfzzzz/o2rUrgPc/fJWUlHD16lUkJydDT08PmZmZOHv2LDw8PLIdp1q1apg7d67CaZEfznx4/vw52rdvj549e8LNzQ27d+/G5MmTUatWrXydhhcYGIiXL1+iT58+MDU1hbOzM/z9/RWSgTNnzsT8+fPRsWNHdOzYEaGhoWjXrh3evn0r1+/evXvYv38/XF1dYWNjg/j4eKxfvx4tWrTAzZs3YW5uLtd/0aJF0NTUxJQpU3Dnzh14e3tDVVUVSkpKeP78OWbPno3z589j8+bNsLGxwcyZM3PclsjISERERMDd3R16enrZ9hk0aBBmzZqFgwcPok+fPnL7sWPHjnBzc0Pfvn2xc+dOjBo1Cmpqahg6dGi+jkV2/P398fbtW/zwww949uwZlixZAjc3N7Rq1QonT57E5MmTpe2eOHGiQvLoQx+fLgYAK1euRFhYGAwMDAC8fw9p0qSJlBgyMjLCoUOHMGzYMCQnJ8PLy0vu8fPmzYOamhomTpyItLS0HGfQCCHQtWtXBAcHY9iwYahTpw6OHDmCSZMm4dGjR1i5cqVc/zNnzmDv3r0YPXo0dHV18dtvv6FXr16IiYmRYs1O1o/qgQMH5tjnQ5s3b8aQIUPQsGFDLFq0CPHx8fj111/x77//4sqVK3KzST/1/b8wFixYgBkzZsDNzQ3ff/89njx5Am9vbzg5OUnxvX37Fi4uLkhLS8MPP/wAU1NTPHr0CAcPHsSLFy+gr6+PLVu24Pvvv0ejRo2k94vcPgOtrKyQkZGBLVu2ZPt+96GgoCB06NAB9evXx6xZs6CkpARfX1+0atUKp0+fRqNGjdCzZ0/cvn1b4fREIyOjXMfO63Wlo6ODHj16YMeOHVixYoVcInnbtm0QQmT7B5PszJ49G05OTli7dm2us6WOHz+ODh06oGLFipg9ezbevHkDb29vODo6IjQ0VEouX79+He3atYORkRFmz56Nd+/eYdasWTAxMVEYMz/HubAGDhyIn3/+GUePHsXw4cMB5P/z6tGjR2jZsiVkMhmmTp0KbW1tbNy4Eerq6tmuKyIiAn379sWIESMwfPhw2NnZ4fXr12jRogUePXqEESNGwNLSEmfPnsXUqVPx+PFjuYusjBgxQnpNjh07FlFRUVi9ejWuXLmCf//9t1hmlBJRKRJERJ+hy5cvCwDi2LFjQgghMjMzRYUKFcS4cePk+s2cOVMAEHv37lUYIzMzUwghxO+//y4AiBUrVuTYJzg4WAAQwcHBcsujoqIEAOHr6yu1DR48WAAQU6ZMURjv9evXCm2LFi0SMplM3L9/X2pzcnISurq6cm0fxiOEEFOnThXq6urixYsXUltCQoJQUVERs2bNUljPh7y8vAQAcfr0aaktJSVF2NjYCGtra5GRkSG1AxCenp65jieEED169BAA5OIRQog3b96IJ0+eSLfnz5/LLX/79q0wMDAQ06ZNk9r69esn7O3ts13PpUuXFPZ5XmbNmiUAiCdPnoiJEyeKSpUqScsaNmwohgwZIoRQ3NZVq1YJAGLr1q1y8To4OAgdHR2RnJwshBBi//79AoBYsmSJ1O/du3eiefPmCrG2bt1a1KpVS6SmpkptmZmZomnTpqJy5cpSW07PuY916tRJNGrUSLrfs2dP0bNnT6GsrCwOHTokhBAiNDRUABB//vmn1K9FixaiRYsW0v3c9muLFi0EAPHHH39IbWlpacLU1FT06tUr1/iydO7cWTg6Okr3fXx8hIqKikhISJDaEhIShJqamujUqZPcc/3nn38WAMTgwYOlttTUVLnnqRDvX4/q6upi7ty5UlvWfqxZs6Z4+/at1N63b18hk8lEhw4d5MZwcHAQVlZWuW5L1vFeuXJlrv309PREvXr1pPtZ+3H58uVSW1pamqhTp44wNjaW4svtWAwePFguvqz3ICMjI7nX3tSpUwUAYW9vL9LT0+W2W01NTe759/Fz4WM7d+4UAOT267Bhw4SZmZlITEyU69unTx+hr68vvddl7f+KFStm+/73sax9O3/+fLn23r17C5lMJu7cuSO1ARBqampybVevXhUAhLe3d67rqVu3rtDX188zHiHev+aNjY1FzZo1xZs3b6T2gwcPCgBi5syZUltRvP/nZenSpQKAiIqKEkIIER0dLZSVlcWCBQvk+l2/fl2oqKhI7VeuXBEAxK5du3IdX1tbW+61lpu4uDhhZGQkAIiqVauKkSNHioCAAIXPgczMTFG5cmXh4uIi99p+/fq1sLGxEW3bts1x+/KS39fVkSNHBADpfTFL7dq1c33+Z/nw86Fly5bC1NRUOqa+vr4CgLh06ZLUP2v9T58+ldquXr0qlJSUxKBBg6S27t27Cw0NDbnnwM2bN4WysrL48KdYfo9zTrKL8WP6+vqibt260v38fl798MMPQiaTiStXrkhtT58+FeXKlVM4llZWVgKAOHz4sNy6582bJ7S1tcXt27fl2qdMmSKUlZVFTEyMEEKI06dPCwDC399frt/hw4ezbSeiLx9P3yOiz5K/vz9MTEzQsmVLAO9POfjuu++wfft2uau77dmzB/b29tnOPsk6FW3Pnj0wNDTEDz/8kGOfwhg1apRC24c1E169eoXExEQ0bdoUQghcuXIFwPti4f/88w+GDh0KS0vLHOMZNGgQ0tLS5E4P2rFjB969e5fnbKW///4bjRo1kjttRUdHBx4eHoiOjsbNmzcLtrGAdDrOx0Vt161bByMjI+n28akyhw4dwtOnT9G3b1+prW/fvrh69Wq2p219qqxi65cuXZL+zenUvb///humpqZysamqqmLs2LF4+fIlTp06JfVTUVGRO+bKysoKz6lnz54hKCgIbm5uSElJQWJiIhITE/H06VO4uLggMjJS4XSgvDRv3hyhoaF49eoVgPczRzp27Ig6derg9OnTAN7PnpLJZNmeppRfOjo6cs8rNTU1NGrUCPfu3cvzsU+fPsWRI0fk9mOvXr2k0+qyHD9+XJrt8+Fz/eNZN8D7ovVZNYkyMjLw9OlT6OjowM7ODqGhoQr9Bw0aJPfX88aNG0MIgaFDh8r1a9y4MR48eIB3797luD1ZV6nS1dXNdbt1dXUVTlNTUVHBiBEjpPtqamoYMWIEEhISEBISkut4uXF1dYW+vr50P+tUzQEDBsjVtGrcuDHevn2b7+fZzZs3MXToUHTr1g3Tp08H8H420549e9ClSxcIIaTncWJiIlxcXJCUlKRwDAYPHpyvmjF///03lJWVMXbsWLn2H3/8EUIIhas2tmnTRm4mT+3ataGnp5fn8zI5OTnP45fl8uXLSEhIwOjRo+VOR+vUqROqVq0qd9pzlsK+/xfG3r17kZmZCTc3N7ljYWpqisqVKyM4OBgApOfHkSNH8Pr160Kv70MmJia4evUqRo4ciefPn2PdunXo168fjI2NMW/ePOmUy7CwMERGRqJfv354+vSpFOOrV6/QunVr/PPPP59UwD8/r6s2bdrA3Nxc7lT/Gzdu4Nq1awWe4Tt79mzExcXJnSL4ocePHyMsLAzu7u4oV66c1F67dm20bdsWf//9N4D3711HjhxB9+7d5T7vq1WrBhcXF7kx83ucP4WOjo70/laQz6vDhw/DwcFB7sIM5cqVy3H2mY2NjcL27dq1C82bN0fZsmXltq9NmzbIyMjAP//8I/XT19dH27Zt5frVr18fOjo6RbIfiOjzwqQUEX12MjIysH37drRs2RJRUVG4c+cO7ty5g8aNGyM+Ph4nTpyQ+t69exc1a9bMdby7d+/Czs6uSIsRq6iooEKFCgrtMTEx0pdUHR0dGBkZoUWLFgAg1fTI+jGVV9xVq1ZFw4YN5b5g+/v7o0mTJnlehfD+/fvZXhWsWrVq0vKCyvqB9/FpP7169cKxY8dw7NixbK/qs3XrVtjY2EBdXV06lra2ttDS0sqxTtinqFu3LqpWrYqAgAD4+/vD1NQUrVq1yrbv/fv3UblyZYWCzB/vp/v378PMzEwhIffxPr5z5w6EEJgxY4Zcos7IyEgq0p+QkFCg7WnevDnevXuHc+fOISIiAgkJCWjevDmcnJzkklLVq1eX+3FUUBUqVFBI0pYtWzZfNTx27NiB9PR01K1bVzrGz549Q+PGjeWOcdb+rFy5stzjjYyMULZsWbm2zMxMrFy5EpUrV4a6ujoMDQ1hZGSEa9euSa+lD32c4M36gW5hYaHQnpmZme0YWbKe63ldQj0lJUUh8WFubq5Q9LpKlSoAkK+6OTkpyPYByNdxS05ORs+ePVG+fHn88ccf0vF/8uQJXrx4AR8fH4Xn8ZAhQwAoPo9tbGzytR3379+Hubm5wn7L6b3p4+0G8ve81NPTy/P4fRgToPh6Bt6/D38c06e8/xdGZGQkhBCoXLmywvEIDw+XjoWNjQ0mTJiAjRs3wtDQEC4uLlizZs0nrRsAzMzMsHbtWjx+/BgRERH47bffYGRkhJkzZ2LTpk1SjMD75OTHMW7cuBFpaWmfFEd+XldKSkro378/9u/fLyXl/P39oaGhAVdX1wKtz8nJCS1btsyxtlRuz5lq1apJCbknT57gzZs3Cu952T02v8f5U7x8+VJ67RXk8+r+/fvZfu/I6btIdu8HkZGROHz4sMK6sq6+m7WuyMhIJCUlwdjYWKHvy5cvi2Q/ENHnhTWliOizk3VZ+e3bt2P79u0Ky/39/dGuXbsiXWdOM6Y+nJX1oQ9ncXzYt23btnj27BkmT56MqlWrQltbG48ePYK7u3uh/ko8aNAgjBs3Dg8fPkRaWhrOnz+P1atXF3icolC1alUA7//y7OjoKLVbWFhIP4yz/gKaJTk5GQcOHEBqamq2X8oDAgKwYMGCT5qxlp1+/fph7dq10NXVxXfffVdiVwHLOsYTJ05U+CtxlrwSih9r0KABNDQ08M8//8DS0hLGxsaoUqUKmjdvjv/9739IS0vD6dOnC1SrKjsfF/POkjUTIjdZiacPnxcfunfvHipWrFigeBYuXIgZM2Zg6NChmDdvHsqVKwclJSV4eXll+1rKKf7CbFdWguTatWs59rl//z6Sk5NRvXr13DajyBTl9mVxd3dHbGwsLl68KFc7K2v/DhgwIMc6Qh8noIvrylqF3b6qVaviypUrePDggULi7lOV1Pt/lszMTMhkMhw6dCjb/fFhsnz58uVwd3fHn3/+iaNHj2Ls2LFYtGgRzp8/n20irSBkMhmqVKmCKlWqoFOnTqhcubJ0JdWs7Vu6dKncbJqc4iwugwYNwtKlS7F//3707dsXAQEB6Ny5s9wsw/yaNWsWnJ2dsX79+k+q5ZRfBTnOhfHw4UMkJSVJn0HF8XmVJbv3g8zMTLRt21bh6rhZspKMmZmZMDY2zvGPVnnVHyOiLw+TUkT02fH394exsTHWrFmjsGzv3r3Yt28f1q1bB01NTdja2uLGjRu5jmdra4sLFy4gPT09x+KYWbM0Pr6aWkFmFF2/fh23b9+Gn5+fXNHwY8eOyfXL+nGeV9wA0KdPH0yYMAHbtm3DmzdvoKqqiu+++y7Px1lZWSEiIkKhPeuqdFZWVnmO8bHOnTvjl19+gb+/f47Jh4/t3bsXqampWLt2rVTQNktERASmT5+Of//995NOO8tOv379MHPmTDx+/BhbtmzJsZ+VlRWuXbuGzMxMuR+ZH+8nKysrnDhxAi9fvpT7YfDxPs46tqqqqtJffz9V1ml0p0+fhqWlpVQYu3nz5khLS4O/vz/i4+Ph5OSU6zhFnfjLEhUVhbNnz2LMmDHSrJAsmZmZGDhwIAICAjB9+nRpf0ZGRsolqZ48eaIw82X37t1o2bKlNBMjy4sXLxSeS0Ut64f3/v378euvv2Z7Gtgff/wB4P3r4kOxsbF49eqV3KyO27dvA4BU+Li4jkVB/PLLL9i/fz/27t0rJZyzGBkZQVdXFxkZGUX2PM5iZWWF48ePK8wy+5T3pux06dIF27Ztw9atWzF16tQ8YwLev54/nlUZERGRr5jy+/5fGLa2thBCwMbGRvrhnptatWqhVq1amD59Os6ePQtHR0esW7cO8+fPB1A0z7+KFSuibNmyePz4sRQj8H6GWl7PmcKsPz+vK+D9DOS6devC398fFSpUQExMDLy9vQu8PgBo0aIFnJ2dsXjxYoULI3z4nPnYrVu3YGhoCG1tbWhoaEBTU1OaSfahjx9b0ONcUFmfhVkJqIJ8XllZWeHOnTsK7dm15cTW1hYvX77Mc122trY4fvw4HB0diy3ZTUSfF56+R0SflTdv3mDv3r3o3LkzevfurXAbM2YMUlJSpCsr9erVC1evXsW+ffsUxsr6S3qvXr2QmJiY7QyjrD5WVlZQVlaWahpk+d///pfv2LP+svnhX/CFEPj111/l+hkZGcHJyQm///47YmJiso0ni6GhITp06ICtW7fC398f7du3z9cP8o4dO+LixYs4d+6c1Pbq1Sv4+PjA2tq6ULM7HB0d0bZtW/j4+ODPP//Mts/H8W/duhUVK1bEyJEjFY7lxIkToaOjUyyn8Nna2mLVqlVYtGgRGjVqlGO/jh07Ii4uDjt27JDa3r17B29vb+jo6EhJlo4dO+Ldu3dYu3at1C8jI0Phx46xsbH0l/WsH2sfevLkSaG2p3nz5rhw4QKCg4OlpJShoSGqVauGxYsXS31yk/Vj7uPE66fKOn4//fSTwjF2c3NDixYtpD5t2rSBqqoqvL295Z4rH151KYuysrLC82nXrl0FrslVWDNnzsTz588xcuRIhRmTISEhWLx4MWrWrIlevXrJLXv37p3c5d7fvn2L9evXw8jICPXr1wdQfMciv44fP47p06dj2rRp6N69u8JyZWVl9OrVC3v27Mk2eV7Y5zHw/rWUkZGh8H68cuVKyGSyfF3pMT969+6NWrVqYcGCBXLvg1lSUlIwbdo0AO9nIxobG2PdunVIS0uT+hw6dAjh4eHZXrnzY/l9/y+Mnj17QllZGXPmzFF4TQgh8PTpUwDvZ6Z+XCutVq1aUFJSktsubW3tfD/3Lly4INWz+9DFixfx9OlT6RS0+vXrw9bWFsuWLVM4xRuQf84U5vmfn9dVloEDB+Lo0aNYtWoVDAwMPuk5lVVbysfHR67dzMwMderUgZ+fn9x23LhxA0ePHkXHjh0BvH9euLi4YP/+/XKf9+Hh4Thy5IjcmPk9zoURFBSEefPmwcbGRqoDVZDPKxcXF5w7dw5hYWFS27Nnzwr0+e3m5oZz584pbDfw/rmQ9dx1c3NDRkYG5s2bp9Dv3bt3pfa+SUTFhzOliOizEhgYiJSUFHTt2jXb5U2aNIGRkRH8/f3x3XffYdKkSdi9ezdcXV0xdOhQ1K9fH8+ePUNgYCDWrVsHe3t7DBo0CH/88QcmTJiAixcvonnz5nj16hWOHz+O0aNHo1u3btDX14erqyu8vb0hk8lga2uLgwcPFqh2QdWqVWFra4uJEyfi0aNH0NPTw549e7KtffLbb7+hWbNmqFevHjw8PGBjY4Po6Gj89ddfcl/6gPenI/Tu3RsAsv2Slp0pU6Zg27Zt6NChA8aOHYty5crBz88PUVFR2LNnT6FPZ9u6dSvat2+P7t27o0OHDmjTpg3Kli2LuLg4HD9+HP/884/0AyA2NhbBwcEKBY2zqKurw8XFBbt27cJvv/1W5Jd4HjduXJ59PDw8sH79eri7uyMkJATW1tbYvXs3/v33X6xatUqaydGlSxc4OjpiypQpiI6ORvXq1bF3795sa6SsWbMGzZo1Q61atTB8+HBUrFgR8fHxOHfuHB4+fIirV68WeFuaN2+OBQsW4MGDB3LJJycnJ6xfvx7W1tZ5nppja2uLMmXKYN26ddDV1YW2tjYaN26c71pAOfH390edOnVyPEWqa9eu+OGHHxAaGop69eph4sSJWLRoETp37oyOHTviypUrOHTokEKytXPnzpg7dy6GDBmCpk2b4vr16/D39y/waYCF1b9/f1y6dAm//vorbt68if79+6Ns2bIIDQ3F77//DgMDA+zevVvheWtubo7FixcjOjoaVapUwY4dOxAWFgYfHx+pb3Edi/zq27cvjIyMULlyZWzdulVuWdu2bWFiYoJffvkFwcHBaNy4MYYPH47q1avj2bNnCA0NxfHjx/Hs2bNCrbtLly5o2bIlpk2bhujoaNjb2+Po0aP4888/4eXlJVfU/FOoqqpi7969aNOmDZycnODm5gZHR0eoqqriv//+Q0BAAMqWLYsFCxZAVVUVixcvxpAhQ9CiRQv07dsX8fHx+PXXX2FtbY3x48fnub6CvP8XlK2tLebPn4+pU6ciOjoa3bt3h66uLqKiorBv3z54eHhg4sSJCAoKwpgxY+Dq6ooqVarg3bt32LJli5RkzFK/fn0cP34cK1asgLm5OWxsbKTC+R/bsmUL/P390aNHD9SvXx9qamoIDw/H77//Dg0NDfz8888A3tdz2rhxIzp06IAaNWpgyJAhKF++PB49eoTg4GDo6enhwIED0voBYNq0aejTpw9UVVXRpUsXhZpRH8rP6ypLv3798NNPP2Hfvn0YNWrUJ322tGjRAi1atJAuevGhpUuXokOHDnBwcMCwYcPw5s0beHt7Q19fH7Nnz5b6zZkzB4cPH0bz5s0xevRo6Q8fNWrUkDtFOL/HOS+HDh3CrVu38O7dO8THxyMoKAjHjh2DlZUVAgMD5Yr55/fz6qeffsLWrVvRtm1b/PDDD9DW1sbGjRthaWmJZ8+e5Wv226RJkxAYGIjOnTvD3d0d9evXx6tXr3D9+nXs3r0b0dHRMDQ0RIsWLTBixAgsWrQIYWFhaNeuHVRVVREZGYldu3bh119/lb4TEdFXogSu8EdElG9dunQRGhoa4tWrVzn2cXd3F6qqqtKlyp8+fSrGjBkjypcvL9TU1ESFChXE4MGD5S5l/vr1azFt2jRhY2MjVFVVhampqejdu7e4e/eu1OfJkyeiV69eQktLS5QtW1aMGDFC3LhxQ+HS7YMHDxba2trZxnbz5k3Rpk0boaOjIwwNDcXw4cOlS5h/fPn3GzduiB49eogyZcoIDQ0NYWdnJ2bMmKEwZlpamihbtqzQ19eXu1x5Xu7evSt69+4tjd+oUSNx8OBBhX744DLY+fHmzRuxatUq4eDgIPT09ISKioowNTUVnTt3Fv7+/uLdu3dCCCGWL18uAIgTJ07kONbmzZsFAPHnn39KbZcuXcp2f+Vm1qxZAoB48uRJrv2y29b4+HgxZMgQYWhoKNTU1EStWrWyXffTp0/FwIEDhZ6entDX1xcDBw6ULsH+cf+7d++KQYMGCVNTU6GqqirKly8vOnfuLHbv3i31CQ4OFgBEcHBwntuXnJwslJWVha6urrR/hRBi69atAoAYOHCgwmNatGihcBn0P//8U1SvXl2oqKjIxd2iRQtRo0YNhTEGDx4srKyscowrJCREAMj2eZslOjpaABDjx48XQgiRkZEh5syZI8zMzISmpqZwdnYWN27cEFZWVnKXqU9NTRU//vij1M/R0VGcO3dOYbuy9uOuXbvk1pvT5dHz+1zJsn//ftG2bVtRtmxZoa6uLipVqiR+/PHHbB+ftR8vX74sHBwchIaGhrCyshKrV69W6JvTsfh4n0dFRQkAYunSpXKPL8h2f7zPAOR4+/D5GB8fLzw9PYWFhYX0vtm6dWvh4+OTZxy5SUlJEePHjxfm5uZCVVVVVK5cWSxdulRkZmbK9cvpvenj50punj9/LmbOnClq1aoltLS0hIaGhqhZs6aYOnWqePz4sVzfHTt2iLp16wp1dXVRrlw50b9/f/Hw4UO5PkX1/p+bpUuXCgAiKipKrn3Pnj2iWbNmQltbW2hra4uqVasKT09PERERIYQQ4t69e2Lo0KHC1tZWaGhoiHLlyomWLVuK48ePy41z69Yt4eTkJDQ1NQWAXPfltWvXxKRJk0S9evVEuXLlhIqKijAzMxOurq4iNDRUof+VK1dEz549hYGBgVBXVxdWVlbCzc1N4XNg3rx5onz58kJJSSnbbf1QQV5XWTp27CgAiLNnz+bY52M5Pd+ynuPZvZ8cP35cODo6Ck1NTaGnpye6dOkibt68qTDGqVOnRP369YWampqoWLGiWLdunfRe9LG8jnNOsl77WTc1NTVhamoq2rZtK3799VeRnJyc7ePy83klxPtj27x5c6Guri4qVKggFi1aJH777TcBQMTFxUn9rKysRKdOnbJdV0pKipg6daqoVKmSUFNTE4aGhqJp06Zi2bJl4u3bt3J9fXx8RP369YWmpqbQ1dUVtWrVEj/99JOIjY3NdT8Q0ZdHJkQ+KmESEVGpeffuHczNzdGlSxeF+jpE9PlwdnZGYmJivurFEVHx6dGjB65fv16gmkdUcF5eXli/fj1evnyZ40UJiIjywppSRESfuf379+PJkydyxXOJiIhI0ePHj/HXX39h4MCBpR3KV+XNmzdy958+fYotW7agWbNmTEgR0SdhTSkios/UhQsXcO3aNcybNw9169ZVuLIZERERvRcVFYV///0XGzduhKqqKkaMGFHaIX1VHBwc4OzsjGrVqiE+Ph6bNm1CcnIyZsyYUdqhEdEXjkkpIqLP1Nq1a7F161bUqVMHmzdvLu1wiIiIPlunTp3CkCFDYGlpCT8/P5iampZ2SF+Vjh07Yvfu3fDx8YFMJkO9evWwadMmODk5lXZoRPSFY00pIiIiIiIiIiIqcawpRUREREREREREJY5JKSIiIiIiIiIiKnFffU2pzMxMxMbGQldXFzKZrLTDISIiIiIiIiL6qgkhkJKSAnNzcygp5Twf6qtPSsXGxsLCwqK0wyAiIiIiIiIi+qY8ePAAFSpUyHH5V5+U0tXVBfB+R+jp6ZVyNEREREREREREX7fk5GRYWFhIOZmcfPVJqaxT9vT09JiUIiIiIiIiIiIqIXmVUWKhcyIiIiIiIiIiKnFMShERERERERERUYljUoqIiIiIiIiIiEock1JERERERERERFTimJQiIiIiIiIiIqISx6QUERERERERERGVOCaliIiIiIiIiIioxDEpRUREREREVMoyMjIwY8YM2NjYQFNTE7a2tpg3bx6EEACA9PR0TJ48GbVq1YK2tjbMzc0xaNAgxMbG5jn2o0ePMGDAABgYGEBTUxO1atXC5cuXpeV79+5Fu3btYGBgAJlMhrCwMIUxJkyYgHLlysHCwgL+/v5yy3bt2oUuXbp82g4gom+SSmkHQERERERE9K1bvHgx1q5dCz8/P9SoUQOXL1/GkCFDoK+vj7Fjx+L169cIDQ3FjBkzYG9vj+fPn2PcuHHo2rWrXILpY8+fP4ejoyNatmyJQ4cOwcjICJGRkShbtqzU59WrV2jWrBnc3NwwfPhwhTEOHDiAgIAAHD16FJGRkRg6dChcXFxgaGiIpKQkTJs2DcePHy+W/UJEXzcmpYiIiIiIiErZ2bNn0a1bN3Tq1AkAYG1tjW3btuHixYsAAH19fRw7dkzuMatXr0ajRo0QExMDS0vLbMddvHgxLCws4OvrK7XZ2NjI9Rk4cCAAIDo6OtsxwsPD4ezsjAYNGqBBgwbw8vJCVFQUDA0N8dNPP2HUqFE5rp+IKDc8fY+Ivhl5TYsH8jd9/WPOzs6QyWQKt6wvlQDw8uVLjBkzBhUqVICmpiaqV6+OdevWyY3DafFERETfrqZNm+LEiRO4ffs2AODq1as4c+YMOnTokONjkpKSIJPJUKZMmRz7BAYGokGDBnB1dYWxsTHq1q2LDRs2FCg2e3t7XL58Gc+fP0dISAjevHmDSpUq4cyZMwgNDcXYsWMLNB4RURbOlCKib0Ze0+KBvKevZ2fv3r14+/atdP/p06ewt7eHq6ur1DZhwgQEBQVh69atsLa2xtGjRzF69GiYm5uja9eunBZPRET0jZsyZQqSk5NRtWpVKCsrIyMjAwsWLED//v2z7Z+amorJkyejb9++0NPTy3Hce/fuYe3atZgwYQJ+/vlnXLp0CWPHjoWamhoGDx6cr9hcXFwwYMAANGzYEJqamvDz84O2tjZGjRqFzZs3Y+3atfD29oahoSF8fHxQo0aNQu0DIvr2MClFRN+MvKbFA3lPX89OuXLl5O5v374dWlpackmps2fPYvDgwXB2dgYAeHh4YP369bh48SK6du3KafFERETfuJ07d8Lf3x8BAQGoUaMGwsLC4OXlBXNzc4XkUXp6Otzc3CCEwNq1a3MdNzMzEw0aNMDChQsBAHXr1sWNGzewbt26fCelAGD27NmYPXu2dH/OnDlo06YNVFVVMX/+fFy/fh0HDx7EoEGDEBISkv8NJ6JvGk/fI6JvRmGmxRfGpk2b0KdPH2hra8utOzAwEI8ePYIQAsHBwbh9+zbatWsHgNPiiYiIvnWTJk3ClClT0KdPH9SqVQsDBw7E+PHjsWjRIrl+WQmp+/fv49ixY7nOkgIAMzMzVK9eXa6tWrVqiImJKXSst27dwtatWzFv3jycPHkSTk5OMDIygpubG0JDQ5GSklLosYno28KZUkT0zSjotPjCuHjxIm7cuIFNmzbJtXt7e8PDwwMVKlSAiooKlJSUsGHDBjg5OQHgtHgiIqJv3evXr6GkJD9nQFlZGZmZmdL9rIRUZGQkgoODYWBgkOe4jo6OiIiIkGu7ffs2rKysChWnEAIjRozAihUroKOjg4yMDKSnp0vxAe/reBIR5QeTUkT0zSjItPjC2rRpE2rVqoVGjRrJtXt7e+P8+fMIDAyElZUV/vnnH3h6esLc3Bxt2rQBwGnxRERE37IuXbpgwYIFsLS0RI0aNXDlyhWsWLECQ4cOBfA+4dO7d2+Ehobi4MGDyMjIQFxcHID3pQTU1NQAAK1bt0aPHj0wZswYAMD48ePRtGlTLFy4EG5ubrh48SJ8fHzg4+MjrfvZs2eIiYlBbGwsAEhJLFNTU5iamsrFuXHjRhgZGUkXYHF0dMTs2bNx/vx5HDp0CNWrV8+18DoRkRzxlUtKShIARFJSUmmHQkSlrEKFCmL16tVybfPmzRN2dnYKfaOiogQAceXKlXyP//LlS6GnpydWrVol1/769WuhqqoqDh48KNc+bNgw4eLiku1Y4eHholKlSiIlJUX8+uuvwtXVVVoHAJGcnJzvuL4G7969E9OnTxfW1tZCQ0NDVKxYUcydO1dkZmZKfTIzM8WMGTOEqamp0NDQEK1btxa3b9/Oc+yHDx+K/v37i3LlygkNDQ1Rs2ZNcenSpXyPm5qaKgYMGCB0dXVF5cqVxbFjx+TGX7JkiRgzZkwR7AUiIvqaJScni3HjxglLS0vps27atGkiLS1NCPF/302yu23fvl2EhISIkJAQYWZmJjw8PKT7ISEhYuXKlcLW1laoqakJa2trMW3aNLnls2bNynZcLy8vuRjj4uKElZWVePTokVz7nDlzRLly5UTVqlXFhQsXSmyfEdHnK7+5GM6UIqJvRn6mxX+KXbt2IS0tDQMGDJBrT09PR3p6er7XLTgtXkF+rpy4ZMkS/Pbbb/Dz84ONjQ1mzJgBFxcX3Lx5ExoaGtmO+/z5czg6OqJly5Y4dOgQjIyMEBkZibJly0p98hrXx8cHISEhOHfuHA4dOoR+/fohPj4eMpkMUVFR2LBhAy5fvlwi+4mIiL5curq6WLVqFVatWpXtcmtrawghFNpjYmJgZ2eH1NRUqe3jmVAfio6OxoIFC7BgwYI8Y1q3bh3Gjx8vXWzFxMQk24vBzJw5EzNnzsxzPCKijzEpRUTfjLymxQP5m74+aNAglC9fXqHw6KZNm9C9e3eF+g56enpo0aIFJk2aBE1NTVhZWeHUqVP4448/sGLFCoU4OS1eUV5XThRCYNWqVZg+fTq6desGAPjjjz9gYmKC/fv3o0+fPtmOu3jxYlhYWMDX11dqs7Gxkf6fn3HDw8PRtWtX1KhRAxUrVsSkSZOQmJgIIyMjjBo1CosXL86zCC0REVFhJSYmyiWkilJqaioSExN5BWAiKjZMShHRN8Pb2xszZszA6NGjkZCQAHNzc4wYMULuL3uBgYEYMmSIdD8rmeHh4YERI0YAAG7evInnz58jNDRU6hcdHY0zZ85gzZo1cu1Zfv75Z6xevRpubm5ITk6GqakpJk6ciJEjR8r1i4+Px4IFC3D27FmprVGjRvjxxx/RqVMnGBsbw8/Pr2h2yBekadOm8PHxwe3bt1GlShXpyolZSb2oqCjExcVJ9bkAQF9fH40bN8a5c+dyTEoFBgbCxcUFrq6uOHXqFMqXL4/Ro0dj+PDh+R7X3t4eW7ZswZs3b3DkyBGYmZnB0NAQ/v7+0NDQQI8ePYpxzxARERERfcFK4FTCUsWaUkT0Ke7fvy80NDRyrOHwKTcNDQ1x//790t7EL0JGRoaYPHmykMlkQkVFRchkMrFw4UJp+b///isAiNjYWLnHubq6Cjc3txzHVVdXF+rq6mLq1KkiNDRUrF+/XmhoaIjNmzfne9y3b9+K0aNHC2tra9GgQQNx+vRp8fTpU1GxYkURExMjpk2bJmxtbUW7du3Ew4cPi2qXfDGsrKyyff6PHj1aCCHEnTt3RPfu3YWhoaHQ1dUVrq6uIi4uLtcx81NjbM+ePaJt27aiXLlyOdaHGz9+vChbtqyoUKGC2Lp1q9yynTt3is6dO3/6DviCFcexEyLvOm6zZs0SdnZ2QktLS5QpU0a0bt1anD9/XlrOOm5E8kJCQorle0rWLSQkpLQ3kYi+QPnNxcgXOCEiIjklMSWe8vbhlRNDQ0Ph5+eHZcuWffKssczMTNSrVw8LFy5E3bp14eHhgeHDh2PdunX5HkNVVRVr1qxBVFQULl26hGbNmuHHH3/E2LFjceXKFezfvx9Xr15FkyZNpPpX35JLly7h8ePH0u3YsWMAAFdXV7x69Qrt2rWDTCZDUFAQ/v33X7x9+xZdunTJtdZbVo2x1atXIzw8HIsXL8aSJUvg7e0t9Xn16hWaNWuGxYsXZzvGgQMHEBAQgKNHj2LJkiX4/vvvpddjUlISpk2bhjVr1hThnvjyFMexy6rjpqqqikOHDuHmzZtYvny5XB23KlWqYPXq1bh+/TrOnDkDa2trtGvXDk+ePAEAuTpuHh4e6Nevn1RnJ6uOW35q5RAREVHp4+l7RET02Zs0aRKmTJkinYZXq1Yt3L9/H4sWLcLgwYOlel/x8fEwMzOTHhcfH486derkOK6ZmRmqV68u11atWjXs2bMHAAo1bnBwMP777z9s3LgRkyZNQseOHaGtrQ03NzesXr26wNv+pTMyMpK7/8svv8DW1hYtWrTAsWPHEB0djStXrkh1t/z8/FC2bFkEBQXJnTb5obxqjAHAwIEDASDbgrwAEB4eDmdnZzRo0AANGjSAl5cXoqKiYGhoiJ9++gmjRo365muoFMexy6uOGwD069dP7v6KFSuwadMmXLt2Da1bt2YdNyIioq8IZ0oREdFnL68rJ9rY2MDU1BQnTpyQlicnJ+PChQtwcHDIcVxHR0epmH2W27dvw8rKqlDjpqamwtPTE+vXr4eysrLClRO/tasmfuzt27fYunUrhg4dCplMhrS0NMhkMqirq0t9NDQ0oKSkhDNnzuQ4TtOmTXHixAncvn0bAKQaYx06dMh3LPb29rh8+TKeP3+OkJAQvHnzBpUqVcKZM2cQGhr6Tc5qy01RHbvAwEA0aNAArq6uMDY2Rt26dbFhw4Zc1+vj4wN9fX3Y29sDeH/szpw5wzpuREREX4OSOZswe/mpCZGZmSlmzJghTE1NhYaGhmjdurW4fft2vtfBmlJE9ClYp+HzMHjwYFG+fHlx8OBBERUVJfbu3SsMDQ3FTz/9JPX55ZdfRJkyZcSff/4prl27Jrp16yZsbGzEmzdvpD6tWrUS3t7e0v2LFy8KFRUVsWDBAhEZGSn8/f2FlpaWXH2h/Iyb5eeffxY//vijdH/Hjh3C0tJSXL16VQwbNkx07NixqHfNF2XHjh1CWVlZPHr0SAghREJCgtDT0xPjxo0Tr169Ei9fvhRjxowRAISHh0eO4+RVY+xDUVFROdaUmjVrlrC1tRU1a9YUe/fuFWlpaaJmzZri8uXLwtvbW1SpUkU0bdpU3Lhxo0i2/0tWVMcurzpuWQ4cOCC0tbWFTCYT5ubm4uLFi9Iy1nEjksfvKkT0OcpvLqZUk1ILFiwQBgYG0o+MXbt2CR0dHfHrr79KfX755Rehr68v9u/fL65evSq6du2a44+B7DApRUSfgl/0Pg/Jycli3LhxwtLSUvojxrRp00RaWprUJ+uPGCYmJkJdXV20bt1aBAcHi5CQEOlmZmYmPDw85NpWrlwpbG1thZqamrC2thbTpk2TW3758mXx/fffCwMDA6GmpiYaNWokgoODFWK8fv26qFSpknj58qXUlpGRIUaNGiX09PREw4YNRWRkZEnsrs9Wu3btFIqHHzlyRFSsWFHIZDKhrKwsBgwYIOrVqydGjhyZ4zjbtm0TFSpUENu2bRPXrl0Tf/zxhyhXrpxCYkOI3JNSH5s9e7bw8vISV69eFSYmJiIhIUH8/vvvol69egXe1q9NUR07VVVV4eDgINf2ww8/iCZNmsi1vXz5UkRGRopz586JoUOHCmtraxEfH5/juO7u7mLVqlXizz//FDVq1BAvX74UM2fOFD179izE1hJ9WfhdhYg+R19EUqpTp05i6NChcm09e/YU/fv3F0K8/4Fhamoqli5dKi1/8eKFUFdXF9u2bcvXOpiUIqJPwS96Xy5eOfHzEh0dLZSUlMT+/fuzXf7kyRPx/PlzIYQQJiYmYsmSJTmOVaFCBbF69Wq5tnnz5gk7OzuFvvlNSoWHh4tKlSqJlJQU8euvvwpXV1chxPvkCACRnJyc6+O/ZkV57CwtLcWwYcPk2v73v/8Jc3PzXGOoVKlSjrPhgoKCRMOGDcW7d+/E+PHjxaRJk4QQQty4cUOUK1cu13GJvgb8rkJEn6Mv4up7edWEiIqKQlxcnFyxTH19fTRu3Bjnzp0rlZiJiOjLwCsnfl58fX1hbGwsFSf/mKGhIcqUKYOgoCAkJCSga9euOY6VV42xghJCYMSIEVixYgV0dHQUaoEB+KbrgRXlscurjltOMjMzkZaWptDOOm5ERERftlK9+t6UKVOQnJyMqlWrSl8kFixYgP79+wMA4uLiAAAmJiZyjzMxMZGWfSwtLU3uS0tycnIxRU9ERET5kZmZCV9fXwwePBgqKvJfPXx9fVGtWjUYGRnh3LlzGDduHMaPHw87OzupT+vWrdGjRw+MGTMGANClSxcsWLAAlpaWqFGjBq5cuYIVK1Zg6NCh0mOePXuGmJgYxMbGAoCUCDE1NZWuqphl48aNMDIyQpcuXQC8T5zMnj0b58+fx6FDh1C9enWUKVOmyPfLl6Coj9348ePRtGlTLFy4EG5ubrh48SJ8fHzg4+MDAHj16hUWLFiArl27wszMDImJiVizZg0ePXoEV1dXhfjmzZuHjh07om7dugDeH7tJkyZhyJAhWL16NRwdHYtr1xAREVERKNWk1M6dO+Hv74+AgADUqFEDYWFh8PLygrm5OQYPHlyoMRctWoQ5c+YUcaRERERUWMePH0dMTIxc0ihLREQEpk6dimfPnsHa2hrTpk3D+PHjERMTI81GCw8PR6VKlRAaGgoAGDZsGN6+fYvvv/8ez58/h6GhIbp164aePXtKfQIDA+W+D/Tp0wcA4OXlhZUrV0rt8fHxWLBgAc6ePSu1NWrUCD/++CM6deoEY2Nj+Pn5Ff1O+UIU9bFTVlbG0qVLsXr1asyZMwfm5uYYP348qlWrhtDQUKSlpeH8+fPYuHEjXrx4AX19fdSoUQMbNmyArq6u3Ppv3LiBnTt3IiwsTGrr3bs3Tp48iebNm8POzg4BAQHFt3OIiIjok8mEEKK0Vm5hYYEpU6bA09NTaps/fz62bt2KW7du4d69e7C1tcWVK1dQp04dqU+LFi1Qp04d/PrrrwpjZjdTysLCAklJSdDT0yvW7SGir09oaCjq169fbOOHhISgXr16xTb+t4zH7ssVExMDOzu7Yjn9UkNDAxEREbC0tCzysYnHjqg08POOiD5HycnJ0NfXzzMXU6o1pfKqCWFjYwNTU1OcOHFCWp6cnIwLFy7AwcEh2zHV1dWhp6cndyMiIqIvB+uBfbl47IiIiKggSvX0vbxqQshkMnh5eWH+/PmoXLkybGxsMGPGDJibm6N79+6lGToREREREREREX2CUk1KeXt7Y8aMGRg9ejQSEhJgbm6OESNGYObMmVKfn376Ca9evYKHhwdevHiBZs2a4fDhw9DQ0CjFyImIiIiIiIiI6FOUalJKV1cXq1atwqpVq3LsI5PJMHfuXMydO7fkAiMiIiIiIiIiomJVqjWliIiIiIiIiIjo28SkFBERERERERERlTgmpYiIiIiIviLW1taQyWQKN09PT6nPuXPn0KpVK2hra0NPTw9OTk548+ZNruOuWbMG1tbW0NDQQOPGjXHx4kW55ampqfD09ISBgQF0dHTQq1cvxMfHS8ufPXuGLl26QEdHB3Xr1sWVK1fkHu/p6Ynly5cXwR4gIqIvBZNSRERERERfkUuXLuHx48fS7dixYwAAV1dXAO8TUu3bt0e7du1w8eJFXLp0CWPGjIGSUs4/DXbs2IEJEyZg1qxZCA0Nhb29PVxcXJCQkCD1GT9+PA4cOIBdu3bh1KlTiI2NRc+ePaXlCxYsQEpKCkJDQ+Hs7Izhw4dLy86fP48LFy7Ay8uriPcGERF9zpiUIiIiIiL6ihgZGcHU1FS6HTx4ELa2tmjRogWA98mjsWPHYsqUKahRowbs7Ozg5uYGdXX1HMdcsWIFhg8fjiFDhqB69epYt24dtLS08PvvvwMAkpKSsGnTJqxYsQKtWrVC/fr14evri7Nnz+L8+fMAgPDwcPTp0wdVqlSBh4cHwsPDAQDp6ekYOXIk1q1bB2Vl5WLeO0RE9DlhUoqIiIiI6Cv19u1bbN26FUOHDoVMJkNCQgIuXLgAY2NjNG3aFCYmJmjRogXOnDmT6xghISFo06aN1KakpIQ2bdrg3LlzAICQkBCkp6fL9alatSosLS2lPvb29ggKCsK7d+9w5MgR1K5dGwCwZMkSODs7o0GDBsWxC4iI6DPGpBRRAeVVp8HZ2Vlh2ciRI3McLz09HZMnT0atWrWgra0Nc3NzDBo0CLGxsXL9unbtCktLS2hoaMDMzAwDBw6U6xMdHQ0nJydoa2vDyckJ0dHRco/v3Lkz9uzZU3Q7goiIiD57+/fvx4sXL+Du7g4AuHfvHgBg9uzZGD58OA4fPox69eqhdevWiIyMzHaMxMREZGRkwMTERK7dxMQEcXFxAIC4uDioqamhTJkyOfaZMmUKVFRUYGtri3379mHTpk2IjIyEn58fZsyYgZEjR6JixYpwc3NDUlJSEe4FIiL6XDEpRVRAedVpAIDhw4fL9VmyZEmO471+/RqhoaGYMWMGQkNDsXfvXkRERKBr165y/Vq2bImdO3ciIiICe/bswd27d9G7d29p+Y8//ojy5csjLCwMZmZmmDhxorRsx44dUFJSQq9evYpqNxAREdEXYNOmTejQoQPMzc0BAJmZmQCAESNGYMiQIahbty5WrlwJOzs76VS84qKvr4+AgADcv38fp06dQvXq1TFixAgsXboU/v7+uHfvHiIiIqClpYW5c+cWayxERPR5UCntAIi+NEZGRnL3f/nlF7k6DQCgpaUFU1PTfI2nr68vJbayrF69Go0aNUJMTAwsLS0BvK//kMXKygpTpkxB9+7dkZ6eDlVVVYSHh2PFihWoXLky3N3dpaTUixcvMH36dAQFBRVqe4mIiOjLdP/+fRw/fhx79+6V2szMzAAA1atXl+tbrVo1xMTEZDuOoaEhlJWV5a6kBwDx8fHS9x1TU1O8ffsWL168kJst9WGfj/n6+qJMmTLo1q0bevbsie7du0NVVRWurq6YOXNmgbeXiIi+PJwpRfQJPq7TkMXf3x+GhoaoWbMmpk6ditevXxdo3KSkJMhkMoUp8FmePXsGf39/NG3aFKqqqgDe12k4fvw4MjMzcfToUalOw6RJk+Dp6QkLC4vCbSQRERF9kXx9fWFsbIxOnTpJbdbW1jA3N0dERIRc39u3b8PKyirbcdTU1FC/fn2cOHFCasvMzMSJEyfg4OAAAKhfvz5UVVXl+kRERCAmJkbq86EnT55g7ty58Pb2BgBkZGQgPT0dwPvSBhkZGYXcaiIi+pIwKUX0CT6u0wAA/fr1w9atWxEcHIypU6diy5YtGDBgQL7HTE1NxeTJk9G3b1/o6enJLZs8eTK0tbVhYGCAmJgY/Pnnn9KyZcuW4datW7C2tkZkZCSWLVuGf/75B2FhYRg0aBDc3NxQsWJFjBw5Em/fvv3kbSciIqLPV2ZmJnx9fTF48GCoqPzfyREymQyTJk3Cb7/9ht27d+POnTuYMWMGbt26hWHDhkn9WrdujdWrV0v3J0yYgA0bNsDPzw/h4eEYNWoUXr16hSFDhgB4P/N72LBhmDBhAoKDgxESEoIhQ4bAwcEBTZo0UYjPy8tLKj0AAI6OjtiyZQvCw8Ph4+MDR0fH4to1RET0GeHpe0Sf4OM6DQDg4eEh/b9WrVowMzND69atcffuXdja2uY6Xnp6Otzc3CCEwNq1axWWT5o0CcOGDcP9+/cxZ84cDBo0CAcPHoRMJkP58uVx8OBBqW9aWhpcXFzg5+eH+fPnQ1dXFxEREWjfvj3Wr1+PH374oQj2ABEREX2Ojh8/jpiYGAwdOlRhmZeXF1JTUzF+/Hg8e/YM9vb2OHbsGFRVVREaGgoACA8PR6VKlaT7lStXxrhx4zBlyhQ8ffoUVapUwapVq/Do0SM8evQIADBo0CA8ffoU3bt3x9u3b+Hg4IApU6bIlSMAgCNHjuDOnTvYsmWL1DZmzBhcvnwZjRs3RqNGjTBr1qzi3D1ERPSZYFKKqJCyq9OQncaNGwMA7ty5k2tSKishdf/+fQQFBSnMkgLe13QwNDRElSpVUK1aNVhYWOD8+fPZTotfuHAh2rVrh/r162P48OGYP38+VFVV0bNnTwQFBTEpRURE9BVr164dhBA5Lp8yZQqmTJki3Y+JiYGdnR1SU1OlNh8fH/j4+GT7+P/++09upnh2goODERwcDA0NDUREREiJKRcXF7i4uMj11dLSws6dO/PaLCIi+sowKUVUSNnVachOWFgYgP8rLJqdrIRUZGQkgoODYWBgkOf6s66ek5aWprAsPDwcAQEB0rpZp4GIiIhyk5iYKJeQKkqpqalITEyUmy1FREQEsKYUUaHkVKfh7t27mDdvHkJCQhAdHY3AwEAMGjQITk5OUuFxAKhatSr27dsH4H2SqHfv3rh8+TL8/f2RkZGBuLg4xMXFSbWfLly4gNWrVyMsLEyaSdW3b1/Y2toqzJISQsDDwwMrV66EtrY2gPd1GjZs2IDw8HD88ccfrNNAREREREREpY4zpYgKIac6DWpqajh+/DhWrVqFV69ewcLCAr169cL06dMRExODxMREAO+vRnP16lVYWVkhNjYWgYGBAIA6derIjbd+/Xo0aNAA0dHR8PPzw/Tp0/HmzRsYGhrCwcEBM2bMQHx8vNxfHn18fGBiYoLOnTtLbbNnz0a/fv3QuHFjtG/fHp6ensW0Z4iIiIiIiIjyh0kpokLIqU6DhYUFTp06pdCeXZ2GOXPmYM6cObmuZ8SIEdm2x8bGYs+ePdizZ49CnYYRI0YoPM7Y2BjHjx/Pc7uIiIiIiIiISgpP3yMqASVRp4GIiIiIiIjoS8KkFBERERERERERlTgmpYiIiIiIiIiIqMQxKUVERERERERERCWOSSkiIiIiIiIiIipxTEoREREREREREVGJY1KKiIiIiIiIiIhKHJNSRERERERERJ/A2toaMplM4ebp6QkA8PHxgbOzM/T09CCTyfDixYsCjf/LL79AJpPBy8tLrn3EiBGwtbWFpqYmjIyM0K1bN9y6dUta/uzZM3Tp0gU6OjqoW7curly5Ivd4T09PLF++vFDbTFQUmJQiIiIiIiIi+gSXLl3C48ePpduxY8cAAK6urgCA169fo3379vj5558LNfb69etRu3ZthWX169eHr68vwsPDceTIEQgh0K5dO2RkZAAAFixYgJSUFISGhsLZ2RnDhw+XHnv+/HlcuHBBIdFFVJJUSjsAIiIiIiIioi+ZkZGR3P1ffvkFtra2aNGiBQBIiZ+TJ08WaNyXL1+if//+2LBhA+bPn6+w3MPDQ/q/tbU15s+fD3t7e0RHR8PW1hbh4eHo06cPqlSpAg8PD/j4+AAA0tPTMXLkSGzcuBHKysoFiomoKHGmFBEREREREVERefv2LbZu3YqhQ4dCJpN90lienp7o1KkT2rRpk2ffV69ewdfXFzY2NrCwsAAA2NvbIygoCO/evcORI0ek2VZLliyBs7MzGjRo8EnxEX0qJqWIiIiIiIiIisj+/fvx4sULuLu7f9I427dvR2hoKBYtWpRrv//973/Q0dGBjo4ODh06hGPHjkFNTQ0AMGXKFKioqMDW1hb79u3Dpk2bEBkZCT8/P8yYMQMjR45ExYoV4ebmhqSkpE+Kl6gwmJQiIiIiIiIiKiKbNm1Chw4dYG5uXugxHjx4gHHjxsHf3x8aGhq59u3fvz+uXLmCU6dOoUqVKnBzc0NqaioAQF9fHwEBAbh//z5OnTqF6tWrY8SIEVi6dCn8/f1x7949REREQEtLC3Pnzi10vESFxaQUERERERERURG4f/8+jh8/ju+///6TxgkJCUFCQgLq1asHFRUVqKio4NSpU/jtt9+goqIiFTIH3ieeKleuDCcnJ+zevRu3bt3Cvn37sh3X19cXZcqUQbdu3XDy5El0794dqqqqcHV1LXC9K6KiwELnREREREREREXA19cXxsbG6NSp0yeN07p1a1y/fl2ubciQIahatSomT56cY3FyIQSEEEhLS1NY9uTJE8ydOxdnzpwBAGRkZCA9PR3A+8LnHya6iEoKk1JEREREREREnygzMxO+vr4YPHgwVFTkf2rHxcUhLi4Od+7cAQBcv34durq6sLS0RLly5QC8T0T16NEDY8aMga6uLmrWrCk3hra2NgwMDKT2e/fuYceOHWjXrh2MjIzw8OFD/PLLL9DU1ETHjh0V4vPy8sKPP/6I8uXLAwAcHR2xZcsWtGvXDj4+PnB0dCzyfUKUFyaliIiIiIiIiD7R8ePHERMTg6FDhyosW7duHebMmSPdd3JyAgAsW7YMLVu2BACEh4ejUqVKCA0NzXb8ly9fIiEhQVr+5MkT/PXXX1i2bBmSk5NhYGCAunXrYsOGDVJNqSxHjhzBnTt3sGXLFqltzJgxuHz5Mho3boxGjRph1qxZn7YDiAqBSSkiIiIiIiKiT9SuXTsIIbJdNnv2bMyePVuuLSYmBnZ2dnIJJB8fH/j4+OS4jpCQEGzbti3bZfHx8Th8+DAOHz4MDQ0NREREwNLSEgDg4uICFxcXuf5aWlrYuXNnfjaNqNiw0DkRERERERFRCUtMTFSY0VRUUlNTkZiYWCxjExWlUk1KWVtbQyaTKdw8PT0BvH8heXp6wsDAADo6OujVqxfi4+NLM2QiIiIiIiIiIioCpZqUunTpEh4/fizdjh07BgBwdXUFAIwfPx4HDhzArl27cOrUKcTGxqJnz56lGTIRERERERERERWBUq0pZWRkJHf/l19+ga2tLVq0aIGkpCRs2rQJAQEBaNWqFYD3l9esVq0azp8/jyZNmpRGyEREREREREREVAQ+m5pSb9++xdatWzF06FDIZDKEhIQgPT0dbdq0kfpUrVoVlpaWOHfuXI7jpKWlITk5We5GRERERERERESfl88mKbV//368ePEC7u7uAIC4uDioqamhTJkycv1MTEwQFxeX4ziLFi2Cvr6+dLOwsCjGqD/No0ePMGDAABgYGEBTUxO1atXC5cuXpeXZ1duSyWRYunRpjmOmpKTAy8sLVlZW0NTURNOmTXHp0iW5Pi9fvsSYMWNQoUIFaGpqonr16li3bp1cnwkTJqBcuXKwsLCAv7+/3LJdu3ahS5cuRbAHiIiIiIiIiOhbVaqn731o06ZN6NChA8zNzT9pnKlTp2LChAnS/eTk5M8yMfX8+XM4OjqiZcuWOHToEIyMjBAZGYmyZctKfR4/fiz3mEOHDmHYsGHo1atXjuN+//33uHHjBrZs2QJzc3Ns3boVbdq0wc2bN1G+fHkA7xNOQUFB2Lp1K6ytrXH06FGMHj0a5ubm6Nq1Kw4cOICAgAAcPXoUkZGRGDp0KFxcXGBoaIikpCRMmzYNx48fL54dQ0RERERERETfhM8iKXX//n0cP34ce/fuldpMTU3x9u1bvHjxQm62VHx8PExNTXMcS11dHerq6sUZbpFYvHgxLCws4OvrK7XZ2NjI9fl4O//880+0bNkSFStWzHbMN2/eYM+ePfjzzz/h5OQEAJg9ezYOHDiAtWvXYv78+QCAs2fPYvDgwXB2dgYAeHh4YP369bh48SK6du2K8PBwODs7o0GDBmjQoAG8vLwQFRUFQ0ND/PTTTxg1ahQsLS2LalcQERERERER0Tfoszh9z9fXF8bGxujUqZPUVr9+faiqquLEiRNSW0REBGJiYuDg4FAaYRapwMBANGjQAK6urjA2NkbdunWxYcOGHPvHx8fjr7/+wrBhw3Ls8+7dO2RkZEBDQ0OuXVNTE2fOnJHuN23aFIGBgXj06BGEEAgODsbt27fRrl07AIC9vT0uX76M58+fIyQkBG/evEGlSpVw5swZhIaGYuzYsZ+49URERERERET0rSv1pFRmZiZ8fX0xePBgqKj838QtfX19DBs2DBMmTEBwcDBCQkIwZMgQODg4fBVX3rt37x7Wrl2LypUr48iRIxg1ahTGjh0LPz+/bPv7+flBV1cXPXv2zHFMXV1dODg4YN68eYiNjUVGRga2bt2Kc+fOyZ0K6O3tjerVq6NChQpQU1ND+/btsWbNGml2lYuLCwYMGICGDRvC3d0dfn5+0NbWxqhRo7Bu3TqsXbsWdnZ2cHR0xH///Ve0O4aIiIiIiIiIvgmlfvre8ePHERMTg6FDhyosW7lyJZSUlNCrVy+kpaXBxcUF//vf/0ohyqKXmZmJBg0aYOHChQCAunXr4saNG1i3bh0GDx6s0P/3339H//79FWZBfWzLli0YOnQoypcvD2VlZdSrVw99+/ZFSEiI1Mfb2xvnz59HYGAgrKys8M8//8DT0xPm5ubS1Q5nz56N2bNnS4+ZM2cO2rRpA1VVVcyfPx/Xr1/HwYMHMWjQILmxiYiIiIiIiIjyo9STUu3atYMQIttlGhoaWLNmDdasWVPCURU/MzMzVK9eXa6tWrVq2LNnj0Lf06dPIyIiAjt27MhzXFtbW5w6dQqvXr1CcnIyzMzM8N1330l1qN68eYOff/4Z+/btk06XrF27NsLCwrBs2TIpKfWhW7duYevWrbhy5Qp+//13ODk5wcjICG5ubhg6dChSUlKgq6tbmN1ARERERERERN+oUj9971vl6OiIiIgIubbbt2/DyspKoe+mTZtQv3592Nvb53t8bW1tmJmZ4fnz5zhy5Ai6desGAEhPT0d6ejqUlOQPvbKyMjIzMxXGEUJgxIgRWLFiBXR0dJCRkYH09HRpLADIyMjId1xERERERERERACTUqVm/PjxOH/+PBYuXIg7d+4gICAAPj4+8PT0lOuXnJyMXbt24fvvv892nNatW2P16tXS/SNHjuDw4cOIiorCsWPH0LJlS1StWhVDhgwBAOjp6aFFixaYNGkSTp48iaioKGzevBl//PEHevTooTD+xo0bYWRkhC5dugB4n0wLCgrC+fPnsXLlSlSvXl3u6ohERERERERERPlR6qfvfasaNmyIffv2YerUqZg7dy5sbGywatUq9O/fX67f9u3bIYRA3759AQAxMTFITEyUloeHh6NSpUoIDQ0FAFy5cgWrV69GQkIC9PT00Lp1a4wePRrXr1+XHvPzzz9j9erVcHNzQ3JyMkxNTTFx4kSMHDlSbt3x8fFYsGABzp49K7U1atQIP/74Izp16gRjY+McC7MTEREREREREeWGSalS1LlzZ3Tu3DnXPh4eHvDw8ADwPiFlZ2eH1NRUuT4+Pj7w8fFReOzTp0+xc+dO7Ny5M9d13L9/H8uWLcPw4cNhaWkptZuYmCA6Olqh/8yZMzFz5sxcxyQiIiIiIiIiyg1P3/uCJCYmKiSkikpqaqrcDCwiIiIiIiKib8GjR48wYMAAGBgYQFNTE7Vq1cLly5el5e7u7pDJZHK39u3b5zrm7NmzFR5TtWpVafmzZ8/www8/wM7ODpqamrC0tMTYsWORlJQk16dLly7Q0dFB3bp1ceXKFbl1eHp6Yvny5UW0F0oHZ0oRERERERER0Tfp+fPncHR0RMuWLXHo0CEYGRkhMjISZcuWlevXvn17+Pr6SvfV1dXzHLtGjRo4fvy4dF9F5f9SMLGxsYiNjcWyZctQvXp13L9/HyNHjkRsbCx2794NAFiwYAFSUlIQGhqKtWvXYvjw4VKy7Pz587hw4QJ+++23T9r+0sakFBERERERERF9kxYvXgwLCwu5hJONjY1CP3V1dZiamhZobBUVlRwfU7NmTezZs0e6b2triwULFmDAgAF49+4dVFRUEB4ejj59+qBKlSrw8PCQyvakp6dj5MiR2LhxI5SVlQsU0+eGp+8RERERERER0TcpMDAQDRo0gKurK4yNjVG3bl1s2LBBod/JkydhbGwMOzs7jBo1Ck+fPs1z7MjISJibm6NixYro378/YmJicu2flJQEPT09aUaVvb09goKC8O7dOxw5cgS1a9cGACxZsgTOzs5o0KBBIbb488KkFBERERERERF9k+7du4e1a9eicuXKOHLkCEaNGoWxY8fKXWm+ffv2+OOPP3DixAksXrwYp06dQocOHZCRkZHjuI0bN8bmzZtx+PBhrF27FlFRUWjevDlSUlKy7Z+YmIh58+ZJFzoDgClTpkBFRQW2trbYt28fNm3ahMjISPj5+WHGjBkYOXIkKlasCDc3N7laVF8Snr5HRERERERERN+kzMxMNGjQAAsXLgQA1K1bFzdu3MC6deswePBgAECfPn2k/rVq1ULt2rVha2uLkydPonXr1tmO26FDB+n/tWvXRuPGjWFlZYWdO3di2LBhcn2Tk5PRqVMnVK9eHbNnz5ba9fX1ERAQINe3VatWWLp0Kfz9/XHv3j1ERERg+PDhmDt37hdZ9JwzpYiIiIiIiIjom2RmZobq1avLtVWrVi3XU+0qVqwIQ0ND3LlzJ9/rKVOmDKpUqaLwmJSUFLRv3x66urrYt28fVFVVcxzD19cXZcqUQbdu3XDy5El0794dqqqqcHV1xcmTJ/Mdy+eESSkiIiIiIiIi+iY5OjoiIiJCru327duwsrLK8TEPHz7E06dPYWZmlu/1vHz5Enfv3pV7THJyMtq1awc1NTUEBgZCQ0Mjx8c/efIEc+fOhbe3NwAgIyMD6enpAN4XPs/tVMLPGZNSRERERERERPRNGj9+PM6fP4+FCxfizp07CAgIgI+PDzw9PQG8TyZNmjQJ58+fR3R0NE6cOIFu3bqhUqVKcHFxkcZp3bo1Vq9eLd2fOHEiTp06hejoaJw9exY9evSAsrIy+vbtC+D/ElKvXr3Cpk2bkJycjLi4OMTFxWWbYPLy8sKPP/6I8uXLA3ifTNuyZQvCw8Ph4+MDR0fH4txNxYY1pYiIiIiIiIjom9SwYUPs27cPU6dOxdy5c2FjY4NVq1ahf//+AABlZWVcu3YNfn5+ePHiBczNzdGuXTuMGDEC//33nzROeHg4KlWqhNDQUADA9evX4efnh6SkJJQtWxZ16tTBxo0b8eDBAzx48ACXL1/GhQsXAACVKlWSiykqKgrW1tbS/SNHjuDOnTvYsmWL1DZmzBhcvnwZjRs3RqNGjTBr1qzi2kXFikkpIiIiIiIiIvpmde7cGZ07d852maamJo4cOSLXFhMTAzs7O6Smpsq1+/j4wMfHR2GMhIQEHD16FEePHs0zFg0NDSgpyZ/U5uLiIjcrCwC0tLSwc+fOPMf73PH0PSIiIiIiIiKifEpMTFRISBWV1NRUJCYmFsvYnyMmpYiIiIiIiIiIqMQxKUVERERERERERCWOSSkiIiIiIiIiIipxTEoREREREREREVGJY1KKiIiIiIiIiIhKHJNSRERERERERERU4piUIiIiIiIiIiKiEsekFBERERERERERlTgmpYiIiIiIiIiIqMQxKUVERERERERERCWOSSkiIiIiIiIiIipxTEoREREREREREVGJY1KKiIiIiIiIiIhKHJNSRERERERERERU4piUIiIiIiIiIiKiEsekFBERERERERERlTgmpYiIiIiIiIiIqMQxKUVERERERERERCWOSSkiIiIiIiIiIipxpZ6UevToEQYMGAADAwNoamqiVq1auHz5srRcCIGZM2fCzMwMmpqaaNOmDSIjI0sxYiIiIiIiIiIi+lSlmpR6/vw5HB0doaqqikOHDuHmzZtYvnw5ypYtK/VZsmQJfvvtN6xbtw4XLlyAtrY2XFxckJqaWoqRExERERERERHRp1ApzZUvXrwYFhYW8PX1ldpsbGyk/wshsGrVKkyfPh3dunUDAPzxxx8wMTHB/v370adPnxKPmYiIiIiIiIiIPl2pzpQKDAxEgwYN4OrqCmNjY9StWxcbNmyQlkdFRSEuLg5t2rSR2vT19dG4cWOcO3euNEImIiIiIiIiIqIiUKpJqXv37mHt2rWoXLkyjhw5glGjRmHs2LHw8/MDAMTFxQEATExM5B5nYmIiLftYWloakpOT5W5ERERERERERPR5KdXT9zIzM9GgQQMsXLgQAFC3bl3cuHED69atw+DBgws15qJFizBnzpyiDJOIiIiIiIiIiIpYqc6UMjMzQ/Xq1eXaqlWrhpiYGACAqakpACA+Pl6uT3x8vLTsY1OnTkVSUpJ0e/DgQTFETkREREREREREn6JUk1KOjo6IiIiQa7t9+zasrKwAvC96bmpqihMnTkjLk5OTceHCBTg4OGQ7prq6OvT09ORuRERERERERET0eSnV0/fGjx+Ppk2bYuHChXBzc8PFixfh4+MDHx8fAIBMJoOXlxfmz5+PypUrw8bGBjNmzIC5uTm6d+9emqETEREREREREdEnKNWkVMOGDbFv3z5MnToVc+fOhY2NDVatWoX+/ftLfX766Se8evUKHh4eePHiBZo1a4bDhw9DQ0OjFCMnIiIiIiIiIqJPUapJKQDo3LkzOnfunONymUyGuXPnYu7cuSUYFRERERERERERFadSrSlFRERERERERETfJialiIiIiIiIiIioxDEpRUREREREREREJY5JKSIiIiIiIiIiKnFMShERERERERERUYljUoqIiIiIiIiIiEock1JERERERERERFTimJQiIiIiIiIiIqISx6QUERERERERERGVOCaliIiIiIiIiIioxDEpRUREREREREREJY5JKSIiIiIiIiIiKnFMShERERERERERUYljUoqIiIiIiIiIiEock1JERERERERERFTimJQiIiIiIiIiIqISx6QUERERERERERGVOCaliIiIiIiIiIioxDEpRUREREREREREJY5JKSIiIiIiIiIiKnFMShERERERERERUYljUoqIiIiIiIiIiEock1JERERERERERFTimJQiIiIiIiIiIqISx6QUERERERERERGVOCaliIiIiIiIiIioxDEpRUREREREREREJY5JKSIiIiIiIiIiKnFMShERERERERERUYljUoqIiIiIiIiIiEock1JERERERERERFTimJQiIiIiIiIiIqISx6QUERERERERERGVOCaliIiIiIiIiIioxDEpRUREREREREREJY5JKSIiIiIiIiIiKnGlmpSaPXs2ZDKZ3K1q1arS8tTUVHh6esLAwAA6Ojro1asX4uPjSzFiIiIiIiIiIiIqCqU+U6pGjRp4/PixdDtz5oy0bPz48Thw4AB27dqFU6dOITY2Fj179izFaImIiIiIiIiIqCiolHoAKiowNTVVaE9KSsKmTZsQEBCAVq1aAQB8fX1RrVo1nD9/Hk2aNCnpUImIiIiIiIiIqIiU+kypyMhImJubo2LFiujfvz9iYmIAACEhIUhPT0ebNm2kvlWrVoWlpSXOnTtXWuESEREREREREVERKNWZUo0bN8bmzZthZ2eHx48fY86cOWjevDlu3LiBuLg4qKmpoUyZMnKPMTExQVxcXI5jpqWlIS0tTbqfnJxcXOETEREREREREVEhlWpSqkOHDtL/a9eujcaNG8PKygo7d+6EpqZmocZctGgR5syZU1QhEhERERERERFRMSjw6XvW1taYO3eudJpdUSpTpgyqVKmCO3fuwNTUFG/fvsWLFy/k+sTHx2dbgyrL1KlTkZSUJN0ePHhQ5HESEREREREREdGnKXBSysvLC3v37kXFihXRtm1bbN++Xe50uU/x8uVL3L17F2ZmZqhfvz5UVVVx4sQJaXlERARiYmLg4OCQ4xjq6urQ09OTuxERERERERER0eelUEmpsLAwXLx4EdWqVcMPP/wAMzMzjBkzBqGhoQUaa+LEiTh16hSio6Nx9uxZ9OjRA8rKyujbty/09fUxbNgwTJgwAcHBwQgJCcGQIUPg4ODAK+8REREREREREX3hCn31vXr16uG3335DbGwsZs2ahY0bN6Jhw4aoU6cOfv/9dwgh8hzj4cOH6Nu3L+zs7ODm5gYDAwOcP38eRkZGAICVK1eic+fO6NWrF5ycnGBqaoq9e/cWNmQiIiIiIiIiIvpMFLrQeXp6Ovbt2wdfX18cO3YMTZo0wbBhw/Dw4UP8/PPPOH78OAICAnIdY/v27bku19DQwJo1a7BmzZrChklERERERERERJ+hAielQkND4evri23btkFJSQmDBg3CypUrUbVqValPjx490LBhwyINlIiIiIiIiIiIvh4FTko1bNgQbdu2xdq1a9G9e3eoqqoq9LGxsUGfPn2KJEAiIiIiIiIiIvr6FDgpde/ePVhZWeXaR1tbG76+voUOioiIiIiIiIiIvm4FLnSekJCACxcuKLRfuHABly9fLpKgiIiIiIiIiIjo61bgpJSnpycePHig0P7o0SN4enoWSVBERERERERERPR1K3BS6ubNm6hXr55Ce926dXHz5s0iCYqIiIiIiIiIiL5uBU5KqaurIz4+XqH98ePHUFEpcIkqIiIiIiIiIiL6BhU4KdWuXTtMnToVSUlJUtuLFy/w888/o23btkUaHBERERERERERfZ0KPLVp2bJlcHJygpWVFerWrQsACAsLg4mJCbZs2VLkARIRERERERER0denwEmp8uXL49q1a/D398fVq1ehqamJIUOGoG/fvlBVVS2OGImIiIiIiIiI6CtTqCJQ2tra8PDwKOpYiIiIiIiIiIjoG1HoyuQ3b95ETEwM3r59K9fetWvXTw6KiIiIiIiIiIi+bgVOSt27dw89evTA9evXIZPJIIQAAMhkMgBARkZG0UZIRERERERERERfnQJffW/cuHGwsbFBQkICtLS08N9//+Gff/5BgwYNcPLkyWIIkYiIiIiIiIiIvjYFnil17tw5BAUFwdDQEEpKSlBSUkKzZs2waNEijB07FleuXCmOOImIiIiIiIiI6CtS4JlSGRkZ0NXVBQAYGhoiNjYWAGBlZYWIiIiijY6IiIiIiIiIiL5KBZ4pVbNmTVy9ehU2NjZo3LgxlixZAjU1Nfj4+KBixYrFESMREREREREREX1lCpyUmj59Ol69egUAmDt3Ljp37ozmzZvDwMAAO3bsKPIAiYiIiIiIiIjo61PgpJSLi4v0/0qVKuHWrVt49uwZypYtK12Bj4iIiIiIiIiIKDcFqimVnp4OFRUV3LhxQ669XLlyTEgREREREREREVG+FSgppaqqCktLS2RkZBRXPERERERERERE9A0o8NX3pk2bhp9//hnPnj0rjniIiIiIiIiIiOgbUOCaUqtXr8adO3dgbm4OKysraGtryy0PDQ0tsuCIiIiIiIiIiOjrVOCkVPfu3YshDCIiIiIiIiIi+pYUOCk1a9as4oiDiIiIiIiIiIi+IQWuKUVERERERERERPSpCpyUUlJSgrKyco43IiIiIiIiKh1TpkzBxYsXkZycjPj4eOzbtw9VqlSR67Nu3TrcuXMHr1+/RkJCAvbv3w87O7tSipiIvmUFPn1v3759cvfT09Nx5coV+Pn5Yc6cOUUWGBERERERERVMixYtsGbNGly6dAkqKipYuHAhjh49iurVq+P169cAgJCQEPj7+yMmJgblypXD7NmzcfToUdjY2CAzM7OUt4CIviUFTkp169ZNoa13796oUaMGduzYgWHDhhVJYERERERERFQwHTp0kLvv7u6OJ0+eoH79+jh9+jQAYMOGDdLy+/fvY/r06bh27Rqsra1x7969Eo2XiL5tRVZTqkmTJjhx4kRRDUdERERERESfSF9fHwDw7NmzbJdraWlhyJAhuHfvHh48eFCSoRERFU1S6s2bN/jtt99Qvnz5ohiOiOizYWJikmddhuHDhyM4OBhJSUkQQkhf/rKjpqaGK1euQAgBe3v74g7/m6ajo4PAwEA8evQIQgiFmb6zZs1CeHg4Xr58iWfPnuHYsWNo1KhRtmPxuBER0ZdIJpNh1apVOHPmDP777z+5ZaNGjUJKSgpevXqFDh06oG3btkhPTy+lSInoW1XgpFTZsmVRrlw56Va2bFno6uri999/x9KlS4sjRiKiUqOjo4M1a9agSZMmaNu2LVRVVXH06FFoaWlJfbS0tHD48GEsXLgwz/GWLFmC2NjY4gyZ/j8lJSVcvXoVnp6e2S6/ffs2xowZg1q1aqFZs2aIjo7G0aNHYWhoqNCXx42IiL5Ea9asQc2aNdGnTx+FZf7+/qhbty6cnJxw+/Zt7Ny5E+rq6qUQJRF9ywpcU2rlypWQyWTSfSUlJRgZGaFx48YoW7ZskQZHRFTa7t69Cz8/P+l+dnUZfv31VwDvC4vmpn379mjXrh169eqFjh07Fl/QBABITk7GjBkzcly+bds2ufsTJkzA999/j9q1ayMoKEhq53EjIqIvkbe3Nzp37gwnJyc8evRIYXlycjKSk5Nx584dnD9/Hs+fP0ePHj2wffv2UoiWiL5VBU5Kubu7F0MYRERfhrzqMuTE2NgYGzZsQPfu3aUr39DnQ1VVFR4eHnjx4gWuXr0qtfO4ERHRl8jb2xs9evSAs7MzoqOj8+wvk8kgk8k4U4qISlyBT9/z9fXFrl27FNp37dolN5uAiOhrk1tdhrxs3rwZ69atQ0hISDFFR4XRqVMnpKSkIDU1FePHj0fbtm3x9OlTaTmPGxERfWnWrFmDAQMGoF+/fkhJSYGJiQlMTEygoaEBALCxscGUKVNQr149WFhYwMHBAbt27cKbN2/w999/l3L0RPStKXBSatGiRdnW2zA2Ns5XPRUioi9VbnUZcvPDDz9AV1cXixYtKqbIqLCCg4NRp04dNG3aFIcPH8bOnTthZGQEgMetNOVVpB4A5syZg9jYWLx+/RrHjh1DpUqVsh2LRepL16xZsyCEkLuFh4dn2/fvv//O8XgTUf6NHj0aZcqUwalTpxAXFyfdvvvuOwBAamoqmjdvjr///ht37tzBjh07kJKSgqZNm+LJkyelHD0RfWsKnJSKiYmBjY2NQruVlRViYmIKHcgvv/wCmUwGLy8vqS01NRWenp4wMDCAjo4OevXqhfj4+EKvg4iosLLqMrRs2TLbugy5adWqFRwcHJCWlob09HTcuXMHAHD58mVYWVkVR7iUT69fv8bdu3dx4cIFfP/993j37h2GDRsGIPfjtnnz5lKM+uuXV5H6n376CWPHjsXIkSPRuHFjvHr1CkeOHMn2tBMWqS99N27cgKmpqXRr1qyZQh8vLy8IIUohOqKvT9apeB/fss5qefz4MTp16gRTU1Ooq6vD0tISAwYMwO3bt0s5ciL6FhU4KWVsbIxr164ptF+9ehUGBgaFCuLSpUtYv349ateuLdc+fvx4HDhwALt27cKpU6cQGxuLnj17FmodRESFlVWXoVWrVvmqy/CxsWPHwt7eHnXq1EGdOnWkYtnfffcdfyx/ZpSUlKTERm7Hbdq0aaUZ5lcvq0j9/v37s13u5eWF+fPnIzAwENevX8egQYNgbm6O7t27y/XLKlI/ceLE4g+acvTu3TvEx8dLtw9PkQUAe3t7/Pjjjxg6dGgpRUhERESlpcCFzvv27YuxY8dCV1cXTk5OAIBTp05h3LhxBT6lBQBevnyJ/v37Y8OGDZg/f77UnpSUhE2bNiEgIACtWrUC8L6eVbVq1XD+/Hk0adKkwOsiIiooCwsLDBgwAN26dZPqMgDv36NSU1MBACYmJjA1NZVOH6pVqxZSUlIQExOD58+f48GDB3Jjvnz5EsD7K/ulp6eX4NZ8W5SUlORO17KxsYG9vT2ePXuGp0+fYtq0aQgMDMTjx49haGgIT09PlC9fXqqbmNtxK+hsOSo6NjY2MDMzw/Hjx6W25ORkXLhwAQ4ODtixYwcAFqn/nFSuXBmPHj1Camoqzp07h6lTp0qvL01NTQQEBMDT05Oz4YmIiL5BBZ4pNW/ePDRu3BitW7eGpqYmNDU10a5dO7Rq1apQNaU8PT3RqVMntGnTRq49JCQE6enpcu1Vq1aFpaUlzp07l+N4aWlp0uVNs25ERIVlZGSUa10GABg5ciTCwsKwceNGAMDp06cRFhaGrl27llbYBEBLSwthYWEICwsDAKxcuRJhYWGYO3cuMjIyULVqVezZswe3b9/GgQMHYGBggObNm+PmzZulGzjlytTUFAAUEhjx8fHSMoBF6j8XFy5cgLu7O9q3b49Ro0bBxsYGp0+fho6ODoD3r8uzZ88iMDCwlCMlIiKi0lDgmVJqamrYsWMH5s+fj7CwMGhqaqJWrVqFqouyfft2hIaG4tKlSwrL4uLioKamhjJlysi1m5iYIC4uLscxFy1ahDlz5hQ4FiKi7ISGhqJ+/fq59pkzZ06B3nfu378PmUz2qaFRHl6+fJnrfu7Vq1eBxuNx+3KwSP3n4/Dhw9L/r1+/jgsXLuD+/ftwc3PDkydP0KpVK9StW7cUI6ScTJkyBT179kTVqlXx5s0bnD17FpMnT5arOxQcHAxnZ2e5x61btw6jRo0q4WiJiOhLVeCkVJbKlSujcuXKhV7xgwcPMG7cOBw7dky6PGlRmDp1KiZMmCDdT05OhoWFRZGNT0RERKUn6w9TH/+RysTERJoV92GR+g9dvnwZ/v7+JRYrKUpKSsLt27dRqVIl1KpVC7a2tnjx4oVcnz179uD06dNo2bJl6QRJAIAWLVpgzZo1uHTpElRUVLBw4UIcPXoU1atXlzsl1sfHBzNnzpTu83RZIiIqiAInpXr16oVGjRph8uTJcu1LlizBpUuXpFoceQkJCUFCQgLq1asntWVkZOCff/7B6tWrceTIEbx9+xYvXryQmy318fT8j6mrq2d79R0iIiL68kVFReHx48do3bo1rl69CgDQ1dVF48aNsXbtWgDvi9RPnz5deoy5uTmOHj2K7777DhcuXOCpYqVIW1sbtra22LJlC3bu3Cmd9pzlxo0b0oVuqHR16NBB7r67uzuePHmC+vXr4/Tp01L769evWQ+MiIgKrcBJqX/++QezZ89WaO/QoQOWL1+e73Fat26N69evy7UNGTIEVatWxeTJk2FhYQFVVVWcOHFCOsUiIiICMTExcHBwKGjYRERE9IXIrUj9gwcPsGrVKkyfPh2RkZGIiorCvHnzEBsbK12tj0XqPx9Lly7FgQMHcP/+fZibm2POnDnIyMjAtm3bkJiYmG0yIyYmplBXOqXipa+vDwB49uyZXHv//v0xYMAAxMXF4cCBA5g3bx7evHlTGiESEdEXqMBJqZcvX0JNTU2hXVVVtUBFxXV1dVGzZk25Nm1tbRgYGEjtw4YNw4QJE1CuXDno6enhhx9+gIODA6+8R18cExMTXLx4Mce6DGXLlsWcOXPQrl07WFpa4smTJ9i/fz9mzJghva5q166NKVOmoFmzZjA0NER0dDTWrVuH3377rTQ3jYioyGUVqc+ycuVKAO+Llw8ZMgRLliyBtrY2fHx8UKZMGZw5cwbt27dXOF2PSl+FChWwbds2GBgY4MmTJzhz5gyaNGmCxMTE0g6NCkAmk2HVqlU4c+YM/vvvP6k9ICAA9+/fR2xsLGrXro3FixfDzs6uwDX7iIjo21XgpFStWrWwY8cOuXPHgfdFy6tXr15kgQHvv4QqKSmhV69eSEtLg4uLC/73v/8V6TqISoKOjk6udRnMzc1hbm6OiRMn4ubNm7CyssK6detgbm4OV1dXAED9+vWRkJCAAQMG4MGDB2jatCl8fHyQkZFRyltHRFS08ipSDwCzZs3CrFmz8jUei9SXnr59+xaoP4/T52nNmjWoWbMmmjVrJte+YcMG6f83btzA48ePERQUhIoVK+LevXslHSYREX2BCpyUmjFjBnr27Im7d++iVatWAIATJ04gICAAu3fv/qRgTp48KXdfQ0MDa9aswZo1az5pXKLSdvfuXfj5+Un3P67L8N9//6F3797S8nv37mHatGnYunUrlJWVkZGRAV9fX7kxo6Ki4ODggJ49e5bYdhAREdG3xdvbG507d4aTk1Oep79euHABAFCpUiUmpYiIKF8KnJTq0qUL9u/fj4ULF2L37t3Q1NSEvb09goKCUK5cueKIkeirk1Ndho/7JCcn5zoTSl9fH8+ePZO7GAARERFRUfD29kaPHj3g7OycrzpfderUAQA8fvy4eAMjIqKvhlJhHtSpUyf8+++/ePXqFe7duwc3NzdMnDhRrigpEWUvp7oMHzIwMMCMGTPg4+OT4zgODg747rvvcu1DREREVBhr1qzBgAED0K9fP6SkpMDExAQmJibQ0NAAAFSsWBHTp09HvXr1YGVlhS5duuCPP/7AqVOnFC5mRERElJNCJaWA91fhGzx4MMzNzbF8+XK0atUK58+fL8rYiL5KWXUZ+vTpk+1yXV1d/PXXX7h582a2V7oEgBo1auDPP//EnDlzcOzYsWKMloiIiL5Fo0ePRpkyZXDq1CnExcVJt++++w4A8PbtW7Rp0wZHjx7FrVu3sHz5cuzZswddunQp5ciJiOhLUqDT9+Li4rB582Zs2rQJycnJcHNzQ1paGvbv31/kRc6JvkZ51WXQ0dHB4cOHkZKSgh49euDdu3cKfapVq4YTJ07Ax8cHCxYsKImwiYiI6BuTV9H5hw8fwtnZuWSCISKir1a+Z0p16dIFdnZ2uHbtGlatWoXY2Fh4e3sXZ2xEX5WsugytWrXKti6Drq4ujh49irdv36Jr167ZXtq8evXqCA4Ohp+fH6ZPn14CURMREREREREVj3zPlDp06BDGjh2LUaNGoXLlysUZE9FXx8LCAgMGDEC3bt2kugwAkJSUhNTUVCkhpaWlhQEDBkBPTw96enoAgCdPniAzMxM1atRAUFAQjhw5ghUrVkhj5FYInYiIiIiIiOhzle+ZUmfOnEFKSgrq16+Pxo0bY/Xq1UhMTCzO2Ii+GkZGRrnWZahXrx6aNGmC2rVr4+7du3J9LCwsAAC9e/eGsbExBg4cKLf80qVLpblpRERERERERIWS76RUkyZNsGHDBjx+/BgjRozA9u3bYW5ujszMTBw7dgwpKSnFGSfRFy00NBQymUzh5ufnBwA4depUtstlMhnu378PAJgzZ062y21sbEpz04iIiIiIqJhERUVBCKFwW716dWmHRlQkCnz1PW1tbQwdOhRnzpzB9evX8eOPP+KXX36BsbExunbtWhwxEhEREREREX1zGjZsCFNTU+nWpk0bAMCuXbtKOTKiolHgpNSH7OzssGTJEjx8+BDbtm0rqpiIiIiIiIiIvnmJiYmIj4+Xbp07d8adO3dw6tSp0g6NqEh8UlIqi7KyMrp3747AwMCiGI6IiIiIiIiIPqCqqooBAwbg999/L+1QiIpMkSSliIiIiIiIiKj4dO/eHWXKlMHmzZtLOxSiIsOkFBEREREREdFnbtiwYTh06BAeP35c2qEQFRmV0g6AiIiIiIiIiHJmaWmJNm3aoGfPnqUdClGR4kwpIiIiIiIios/YkCFDkJCQgL/++qu0QyEqUkxKEREREREREX2mZDIZhgwZAj8/P2RkZJR2OERFikmpL4iOjg4CAwPx6NEjCCHQrVs3ueVCiGxvEydOlPpUrlwZ+/fvx5MnT5CUlITTp0/D2dm5hLeEiIiIiIiI8qNNmzawsrLiVffoq8Sk1BdESUkJV69ehaenZ7bLTU1N5W5DhgxBZmYm9uzZI/U5ePAgVFRU0KpVK9SvXx9Xr17FwYMHYWJiUlKbQURERERERPl07NgxyGQyREZGlnYoREWOhc6/IMnJyZgxY0aOy+Pj4+Xud+vWDcHBwYiKigIAGBgYoEqVKhg2bBiuX78OAJgyZQo8PT1Rs2bN4guciIiIiIiIiOgjnCn1lTI2NkanTp2wadMmqe3p06e4desWBg0aBC0tLSgrK2PEiBGIj49HSEhIKUZLRERERERERN8azpT6Sg0ePBgpKSnYu3evXHubNm2wf/9+pKSkIDMzEwkJCWjfvj1evHhROoESERERERER0TeJM6W+UkOHDoW/vz/S0tLk2tesWYOEhAQ0b94cjRo1wv79+3HgwAGYmpqWUqREREREREREX64pU6bg4sWLSE5ORnx8PPbt24cqVarI9alYsSL27t2LhIQEJCUlYceOHTA2Ni6liD8fTEp9hZo1a4aqVati48aNcu2tWrVC586d0adPH5w9exZXrlyBp6cn3rx5g8GDB5dStERERERERERfrhYtWmDNmjVo0qQJ2rZtC1VVVRw9ehRaWloAAC0tLRw9ehRCCLRq1QqOjo5QU1PDgQMHIJPJSjn60sXT975Cw4YNw+XLl3Ht2jW59qwXRGZmplx7ZmYmlJSYnyQiIiIiIiIqqA4dOsjdd3d3x5MnT1C/fn2cPn0ajo6OsLa2Rt26dZGSkgLgfcmd58+fo1WrVjhx4kRphP1ZYCbiC6KkpAR7e3vY29sDAGxsbGBvbw8LCwupj66uLlxdXRVmSQHAuXPn8Pz5c/j5+aF27dqoXLkylixZAhsbG/z1118lth1EREREREREXyt9fX0AwLNnzwAA6urqEELIlddJTU1FZmYmmjVrVioxfi6YlPqCaGlpISwsDGFhYQCAlStXIiwsDHPnzpX69OnTBzKZDNu2bVN4/NOnT9G+fXvo6OggKCgIly9fRrNmzdCtWzeFWVVEREREREREVDAymQyrVq3CmTNn8N9//wEAzp8/j1evXmHx4sXQ1NSElpYWli1bBhUVFZiZmZVyxKWLp+99QV6+fJnn+aYbNmzAhg0bclweEhKC9u3bF3VoRERERERERN+8NWvWoGbNmnIzoBITE+Hq6oq1a9di7NixyMzMxLZt2xASEqJQXudbw6QUEREREREREdEn8vb2RufOneHk5IRHjx7JLTt27BgqVaoEAwMDvHv3DklJSXj8+DHu3btXStF+HpiUIiIiIiIiIiL6BN7e3ujRowecnZ0RHR2dY7+nT58CAFq2bAljY2MEBgaWUISfJyaliIiIiIiIiIgKac2aNejXrx+6deuGlJQUmJiYAACSkpKQmpoK4P0V+cLDw/HkyRM4ODjg119/xcqVK3H79u3SDL3UMSlFRERERERERFRIo0ePBgCcOnVKrt3d3R1+fn7/r707j6qyTvw4/rmiLMPmSHEBFcFMwB0w7eZojjIapzwyOaaNk7hVpwMVkVnUaOaGOpW2uOQcB2cqxlYxKyWHUVxSVBL3cMmtDKhTgDCJBvf3R7+5Z26Q4PY898r7dc7zx/0+3/vwge/YcD88iyQpKipKmZmZatOmjU6cOKHZs2drwYIFhmd1NZRSAAAAAAAAl6mxB5JJUkZGhjIyMgxI415amB0AAAAAAAAAzQ+lFAAAAAAAAAxHKQUAAAAAAADDmVpKLVmyRD169FBAQIACAgJks9m0du1ax/5z584pJSVFQUFB8vPz04gRI1RaWmpiYgAAAAAAAFwNppZS7dq109y5c1VYWKhdu3Zp0KBBGj58uA4cOCBJeuyxx7RmzRq98847ys/P15kzZ3T33XebGRkAAAAAAABXgalP3xs2bJjT69mzZ2vJkiXavn272rVrp+XLlys7O1uDBg2SJGVlZSkmJkbbt2/XrbfeakZkAAAAAAAAXAUuc0+p2tparVy5UtXV1bLZbCosLNSFCxeUkJDgmBMdHa3w8HBt27bNxKQAAAAAAAC4UqaeKSVJ+/btk81m07lz5+Tn56dVq1apS5cuKioqkqenp1q3bu0032q1qqSk5BePV1NTo5qaGsfrysrKaxUdAAAAAAAAl8n0M6WioqJUVFSkgoICPfTQQ0pOTtbBgwcv+3iZmZkKDAx0bO3bt7+KaQEAAAAAAHA1mF5KeXp6qlOnToqPj1dmZqZ69uypl156SSEhITp//rzKy8ud5peWliokJOQXj5eRkaGKigrHdvr06Wv8HQAAAAAAAOBSmV5K/VxdXZ1qamoUHx+vVq1aKS8vz7GvuLhYp06dks1m+8X3e3l5KSAgwGkDAAAAAACAazH1nlIZGRlKTExUeHi4zp49q+zsbG3cuFG5ubkKDAzUxIkTlZ6erjZt2iggIEAPP/ywbDYbT94DAAAAAABwc6aWUmVlZRo7dqy+/vprBQYGqkePHsrNzdXvfvc7SdKCBQvUokULjRgxQjU1NRo6dKgWL15sZmQAAAAAAABcBaaWUsuXL7/ofm9vby1atEiLFi0yKBEAAAAAAACM4HL3lAIAAAAAAMD1j1IKAAAAAAAAhqOUAgAAAAAAgOEopQAAAAAAAGA4SikAAAAAAAAYjlIKAAAAAAAAhqOUAgAAAAAAgOEopQAAAAAAAGA4SikAAAAAAAAYjlIKAAAAAAAAhqOUAgAAAAAAgOEopQAAAAAAAGA4SikAAAAAAAAYjlIKAAAAAAAAhqOUAgAAAAAAgOEopQAAAAAAAGA4SikAAAAAAAAYjlIKAAAAAAAAhqOUAgAAAAAAgOEopQAAAAAAAGA4SikAAAAAAAAYjlIKAAAAAAAAhqOUAgAAAAAAgOEopQAAAAAAAGA4SikAAAAAAAAYjlIKAAAAAAAAhqOUAgAAAAAAgOEopQAAAAAAAGA4SikAAAAAAAAYjlIKAAAAAAAAhqOUAgAAAAAAgOEopQAAAAAAAGA4SikAAAAAAAAYjlIKAAAAAAAAhqOUAgAAAAAAgOEopQAAAAAAAGA4U0upzMxM3XLLLfL391dwcLCSkpJUXFzsNOfcuXNKSUlRUFCQ/Pz8NGLECJWWlpqUGAAAAAAAAFeDqaVUfn6+UlJStH37dq1fv14XLlzQkCFDVF1d7Zjz2GOPac2aNXrnnXeUn5+vM2fO6O677zYxNQAAAAAAAK5USzO/+Lp165xer1ixQsHBwSosLNSAAQNUUVGh5cuXKzs7W4MGDZIkZWVlKSYmRtu3b9ett95qRmwAAAAAAABcIZe6p1RFRYUkqU2bNpKkwsJCXbhwQQkJCY450dHRCg8P17Zt2xo8Rk1NjSorK502AAAAAAAAuBaXKaXq6uqUlpamfv36qVu3bpKkkpISeXp6qnXr1k5zrVarSkpKGjxOZmamAgMDHVv79u2vdXQAAAAAAABcIpcppVJSUrR//36tXLnyio6TkZGhiooKx3b69OmrlBAAAAAAAABXi6n3lPqv1NRUffjhh9q0aZPatWvnGA8JCdH58+dVXl7udLZUaWmpQkJCGjyWl5eXvLy8rnVkAAAAAAAAXAFTz5Sy2+1KTU3VqlWr9O9//1uRkZFO++Pj49WqVSvl5eU5xoqLi3Xq1CnZbDaj4wIAAAAAAOAqMfVMqZSUFGVnZ2v16tXy9/d33CcqMDBQPj4+CgwM1MSJE5Wenq42bdooICBADz/8sGw2G0/eAwAAAAAAcGOmllJLliyRJA0cONBpPCsrS+PGjZMkLViwQC1atNCIESNUU1OjoUOHavHixQYnBQAAAAAAwNVkaillt9sbnePt7a1FixZp0aJFBiQCAAAAAACAEVzm6XsAAAAAAABoPiilAAAAAAAAYDhKKQAAAAAAABiOUgoAAAAAAACGo5QCAAAAAACA4SilAAAAAAAAYDhKKQAAAAAAABiOUgoAAAAAAACGo5QCAAAAAACA4SilAAAAAAAAYDhKKQAAAAAAABiOUgoAAAAAAACGo5QCAAAAAACA4SilAAAAAAAAYDhKKQAAAAAAABiOUgoAAAAAAACGo5QCAAAAAACA4SilAAAAAAAAYDhKKQAAAAAAABiOUgoAAAAAAACGo5QCAAAAAACA4SilAAAAAAAAYDhKKQAAAAAAABiOUgoAAAAAAACGo5QCAAAAAACA4SilAAAAAAAAYDhKKQAAAAAAABiOUgoAAAAAAACGo5QCAAAAAACA4SilAAAAAAAAYDhKKQAAAAAAABiOUgoAAAAAAACGo5QCAAAAAACA4SilAAAAAAAAYDhKKQAAAAAAABiOUgoAAAAAAACGM7WU2rRpk4YNG6awsDBZLBbl5OQ47bfb7Zo2bZpCQ0Pl4+OjhIQEHTlyxJywAAAAAAAAuGpMLaWqq6vVs2dPLVq0qMH98+fP18svv6ylS5eqoKBAvr6+Gjp0qM6dO2dwUgAAAAAAAFxNLc384omJiUpMTGxwn91u18KFC/XnP/9Zw4cPlyT94x//kNVqVU5OjkaPHm1kVAAAAAAAAFxFLntPqePHj6ukpEQJCQmOscDAQPXt21fbtm37xffV1NSosrLSaQMAAAAAAIBrcdlSqqSkRJJktVqdxq1Wq2NfQzIzMxUYGOjY2rdvf01zAgAAAAAA4NK5bCl1uTIyMlRRUeHYTp8+bXYkAAAAAAAA/IzLllIhISGSpNLSUqfx0tJSx76GeHl5KSAgwGkDAAAAAACAa3HZUioyMlIhISHKy8tzjFVWVqqgoEA2m83EZAAAAAAAALhSpj59r6qqSkePHnW8Pn78uIqKitSmTRuFh4crLS1Ns2bN0s0336zIyEhNnTpVYWFhSkpKMi80AAAAAAAArpippdSuXbv029/+1vE6PT1dkpScnKwVK1ZoypQpqq6u1gMPPKDy8nL95je/0bp16+Tt7W1WZAAAAAAAAFwFppZSAwcOlN1u/8X9FotFM2bM0IwZMwxMBQAAAAAAgGvNZe8pBQAAAAAAgOsXpRQAAAAAAAAMRykFAAAAAAAAw1FKAQAAAAAAwHCUUgAAAAAAADAcpRQAAAAAAAAMRykFAAAAAAAAw1FKAQAAAAAAwHCUUgAAAAAAADAcpRQAAAAAAAAMRykFAAAAAAAAw1FKAQAAAAAAwHCUUgAAAAAAADAcpRQAAAAAAAAMRykFAAAAAAAAw1FKAQAAAAAAwHCUUgAAAAAAADAcpRQAAAAAAAAMRykFAAAAAAAAw1FKAQAAAAAAwHCUUgAAAAAAADAcpRQAAAAAAAAMRykFAAAAAAAAw1FKAQAAAAAAwHCUUgAAAAAAADAcpRQAAAAAAAAMRykFAAAAAAAAw1FKAQAAAAAAwHCUUgAAAAAAADAcpRQAAAAAAAAMRykFAAAAAAAAw1FKAQAAAAAAwHCUUgAAAAAAADAcpRQAAAAAAAAMRykFAAAAAAAAw7lFKbVo0SJFRETI29tbffv21Y4dO8yOBAAAAAAAgCvg8qXUW2+9pfT0dD377LP67LPP1LNnTw0dOlRlZWVmRwMAAAAAAMBlcvlS6sUXX9T999+v8ePHq0uXLlq6dKl+9atf6W9/+5vZ0QAAAAAAAHCZXLqUOn/+vAoLC5WQkOAYa9GihRISErRt2zYTkwEAAAAAAOBKtDQ7wMV8++23qq2tldVqdRq3Wq36/PPPG3xPTU2NampqHK8rKiokSZWVldcuqEGqqqqu+fGvh5+TK2Lt3Bdr575YO/fF2rkv1s59sXbui7VzX6yd+2LtGvff/Ha7/aLzLPbGZpjozJkzatu2rT799FPZbDbH+JQpU5Sfn6+CgoJ675k+fbqee+45I2MCAAAAAADgZ06fPq127dr94n6XPlPqhhtukIeHh0pLS53GS0tLFRIS0uB7MjIylJ6e7nhdV1en7777TkFBQbJYLNc0ryuprKxU+/btdfr0aQUEBJgdB5eAtXNfrJ37Yu3cF2vnvlg798XauS/Wzn2xdu6rua6d3W7X2bNnFRYWdtF5Ll1KeXp6Kj4+Xnl5eUpKSpL0U8mUl5en1NTUBt/j5eUlLy8vp7HWrVtf46SuKyAgoFn9D/96wtq5L9bOfbF27ou1c1+snfti7dwXa+e+WDv31RzXLjAwsNE5Ll1KSVJ6erqSk5PVu3dv9enTRwsXLlR1dbXGjx9vdjQAAAAAAABcJpcvpUaNGqVvvvlG06ZNU0lJiXr16qV169bVu/k5AAAAAAAA3IfLl1KSlJqa+ouX66FhXl5eevbZZ+tdygjXx9q5L9bOfbF27ou1c1+snfti7dwXa+e+WDv3xdpdnEs/fQ8AAAAAAADXpxZmBwAAAAAAAEDzQykFAAAAAAAAw1FKAQAAAAAAwHCUUteZTZs2adiwYQoLC5PFYlFOTo7ZkdBEmZmZuuWWW+Tv76/g4GAlJSWpuLjY7FhogiVLlqhHjx4KCAhQQECAbDab1q5da3YsXKK5c+fKYrEoLS3N7ChogunTp8tisTht0dHRZsdCE3311Vf605/+pKCgIPn4+Kh79+7atWuX2bHQiIiIiHr/7iwWi1JSUsyOhouora3V1KlTFRkZKR8fH910002aOXOmuLWwezh79qzS0tLUoUMH+fj46LbbbtPOnTvNjtWsNfaZ2263a9q0aQoNDZWPj48SEhJ05MgRc8K6AUqp60x1dbV69uypRYsWmR0Flyg/P18pKSnavn271q9frwsXLmjIkCGqrq42Oxoa0a5dO82dO1eFhYXatWuXBg0apOHDh+vAgQNmR0MT7dy5U6+99pp69OhhdhRcgq5du+rrr792bFu2bDE7Eprg+++/V79+/dSqVSutXbtWBw8e1AsvvKBf//rXZkdDI3bu3On0b279+vWSpJEjR5qcDBczb948LVmyRK+++qoOHTqkefPmaf78+XrllVfMjoYmmDRpktavX6/XX39d+/bt05AhQ5SQkKCvvvrK7GjNVmOfuefPn6+XX35ZS5cuVUFBgXx9fTV06FCdO3euwfknTpyQxWK5lpFdGk/fu45ZLBatWrVKSUlJZkfBZfjmm28UHBys/Px8DRgwwOw4uERt2rTRX/7yF02cONHsKGhEVVWV4uLitHjxYs2aNUu9evXSwoULzY6FRkyfPl05OTkqKioyOwou0VNPPaWtW7dq8+bNZkfBFUpLS9OHH36oI0eONOsPVK7urrvuktVq1fLlyx1jI0aMkI+Pj9544w0Tk6ExP/zwg/z9/bV69WrdeeedjvH4+HglJiZq1qxZJqaDVP8zt91uV1hYmB5//HFNnjxZklRRUSGr1aoVK1Zo9OjR9Y5x4sQJRUZGNtuzFzlTCnBRFRUVkn4qN+A+amtrtXLlSlVXV8tms5kdB02QkpKiO++8UwkJCWZHwSU6cuSIwsLC1LFjR40ZM0anTp0yOxKa4IMPPlDv3r01cuRIBQcHKzY2Vn/961/NjoVLdP78eb3xxhuaMGEChZSLu+2225SXl6fDhw9Lkvbs2aMtW7YoMTHR5GRozI8//qja2lp5e3s7jfv4+HB2sIs6fvy4SkpKnH6vDAwMVN++fbVt2zYTk7mulmYHAFBfXV2d0tLS1K9fP3Xr1s3sOGiCffv2yWaz6dy5c/Lz89OqVavUpUsXs2OhEStXrtRnn33GvRncUN++fbVixQpFRUXp66+/1nPPPaf+/ftr//798vf3NzseLuKLL77QkiVLlJ6erqefflo7d+7UI488Ik9PTyUnJ5sdD02Uk5Oj8vJyjRs3zuwoaMRTTz2lyspKRUdHy8PDQ7W1tZo9e7bGjBljdjQ0wt/fXzabTTNnzlRMTIysVqv++c9/atu2berUqZPZ8dCAkpISSZLVanUat1qtjn1wRikFuKCUlBTt37+fv4C4kaioKBUVFamiokLvvvuukpOTlZ+fTzHlwk6fPq1HH31U69evr/cXSLi+//0Lf48ePdS3b1916NBBb7/9NpfNuri6ujr17t1bc+bMkSTFxsZq//79Wrp0KaWUG1m+fLkSExMVFhZmdhQ04u2339abb76p7Oxsde3aVUVFRUpLS1NYWBj/5tzA66+/rgkTJqht27by8PBQXFyc7r33XhUWFpodDVega9euOnnypCQ5Ltvz8/Nz7O/fv3+zeXASpRTgYlJTU/Xhhx9q06ZNateundlx0ESenp6Ov1jFx8dr586deumll/Taa6+ZnAy/pLCwUGVlZYqLi3OM1dbWatOmTXr11VdVU1MjDw8PExPiUrRu3VqdO3fW0aNHzY6CRoSGhtYr7GNiYvTee++ZlAiX6uTJk/rXv/6l999/3+woaIInnnhCTz31lONeNt27d9fJkyeVmZlJKeUGbrrpJuXn56u6ulqVlZUKDQ3VqFGj1LFjR7OjoQEhISGSpNLSUoWGhjrGS0tL1atXL8frjz/+WBcuXJD00xNpBw4c6HSfTB8fH0PyugJKKcBF2O12Pfzww1q1apU2btyoyMhIsyPhCtTV1ammpsbsGLiIwYMHa9++fU5j48ePV3R0tJ588kkKKTdTVVWlY8eO6b777jM7ChrRr18/FRcXO40dPnxYHTp0MCkRLlVWVpaCg4OdbrwM1/Wf//xHLVo430rYw8NDdXV1JiXC5fD19ZWvr6++//575ebmav78+WZHQgMiIyMVEhKivLw8RwlVWVmpgoICPfTQQ455//v/eS1b/lTLNNdLMimlrjNVVVVOfyU+fvy4ioqK1KZNG4WHh5uYDI1JSUlRdna2Vq9eLX9/f8c1x4GBgc2qKXdHGRkZSkxMVHh4uM6ePavs7Gxt3LhRubm5ZkfDRfj7+9e7Z5uvr6+CgoK4l5sbmDx5soYNG6YOHTrozJkzevbZZ+Xh4aF7773X7GhoxGOPPabbbrtNc+bM0T333KMdO3Zo2bJlWrZsmdnR0AR1dXXKyspScnKy44MUXNuwYcM0e/ZshYeHq2vXrtq9e7defPFFTZgwwexoaILc3FzZ7XZFRUXp6NGjeuKJJxQdHa3x48ebHa3Zauwzd1pammbNmqWbb75ZkZGRmjp1qsLCwhxP6MPP2HFd2bBhg11SvS05OdnsaGhEQ+smyZ6VlWV2NDRiwoQJ9g4dOtg9PT3tN954o33w4MH2Tz75xOxYuAy33367/dFHHzU7Bppg1KhR9tDQULunp6e9bdu29lGjRtmPHj1qdiw00Zo1a+zdunWze3l52aOjo+3Lli0zOxKaKDc31y7JXlxcbHYUNFFlZaX90UcftYeHh9u9vb3tHTt2tD/zzDP2mpoas6OhCd566y17x44d7Z6envaQkBB7SkqKvby83OxYzVpjn7nr6ursU6dOtVutVruXl5d98ODBF/1v5vHjx+3NuZqx2O3/f1ctAAAAAAAAwCAtGp8CAAAAAAAAXF2UUgAAAAAAADAcpRQAAAAAAAAMRykFAAAAAAAAw1FKAQAAAAAAwHCUUgAAAAAAADAcpRQAAAAAAAAMRykFAAAAAAAAw1FKAQAAXEURERFauHDhVT3miRMnZLFYVFRUdFWPCwAAYCZKKQAA0KyMGzdOFotFc+fOdRrPycmRxWIxKRUAAEDzQykFAACaHW9vb82bN0/ff/+92VFcyvnz582OAAAAmhFKKQAA0OwkJCQoJCREmZmZF5333nvvqWvXrvLy8lJERIReeOEFp/1lZWUaNmyYfHx8FBkZqTfffLPeMcrLyzVp0iTdeOONCggI0KBBg7Rnz56Lft0dO3YoNjZW3t7e6t27t3bv3l1vzv79+5WYmCg/Pz9ZrVbdd999+vbbbx37z549qzFjxsjX11ehoaFasGCBBg4cqLS0NMeciIgIzZw5U2PHjlVAQIAeeOABSdKWLVvUv39/+fj4qH379nrkkUdUXV3teF9NTY0mT56stm3bytfXV3379tXGjRsv+j0BAAD8HKUUAABodjw8PDRnzhy98sor+vLLLxucU1hYqHvuuUejR4/Wvn37NH36dE2dOlUrVqxwzBk3bpxOnz6tDRs26N1339XixYtVVlbmdJyRI0eqrKxMa9euVWFhoeLi4jR48GB99913DX7dqqoq3XXXXerSpYsKCws1ffp0TZ482WlOeXm5Bg0apNjYWO3atUvr1q1TaWmp7rnnHsec9PR0bd26VR988IHWr1+vzZs367PPPqv39Z5//nn17NlTu3fv1tSpU3Xs2DHdcccdGjFihPbu3au33npLW7ZsUWpqquM9qamp2rZtm1auXKm9e/dq5MiRuuOOO3TkyJFGf/YAAAD/ZbHb7XazQwAAABhl3LhxKi8vV05Ojmw2m7p06aLly5crJydHv//97/XfX43GjBmjb775Rp988onjvVOmTNFHH32kAwcO6PDhw4qKitKOHTt0yy23SJI+//xzxcTEaMGCBUpLS9OWLVt05513qqysTF5eXo7jdOrUSVOmTHGcmfS/li1bpqefflpffvmlvL29JUlLly7VQw89pN27d6tXr16aNWuWNm/erNzcXMf7vvzyS7Vv317FxcUKDQ1VUFCQsrOz9Yc//EGSVFFRobCwMN1///2OG7FHREQoNjZWq1atchxn0qRJ8vDw0GuvveYY27Jli26//XZVV1errKxMHTt21KlTpxQWFuaYk5CQoD59+mjOnDmXvTYAAKB5aWl2AAAAALPMmzdPgwYNqncmkiQdOnRIw4cPdxrr16+fFi5cqNraWh06dEgtW7ZUfHy8Y390dLRat27teL1nzx5VVVUpKCjI6Tg//PCDjh071mCmQ4cOqUePHo5CSpJsNpvTnD179mjDhg3y8/Or9/5jx47phx9+0IULF9SnTx/HeGBgoKKiourN7927d71j79271+lSRLvdrrq6Oh0/flxffPGFamtr1blzZ6f31dTU1Ps+AQAALoZSCgAANFsDBgzQ0KFDlZGRoXHjxl3141dVVSk0NLTB+y39b3l1OccdNmyY5s2bV29faGiojh492uRj+fr61jv2gw8+qEceeaTe3PDwcO3du1ceHh4qLCyUh4eH0/6GSjIAAIBfQikFAACatblz56pXr171ziKKiYnR1q1bnca2bt2qzp07y8PDQ9HR0frxxx9VWFjouHyvuLhY5eXljvlxcXEqKSlRy5YtFRER0aQ8MTExev3113Xu3DnH2VLbt293mhMXF6f33ntPERERatmy/q9zHTt2VKtWrbRz506Fh4dL+unyvcOHD2vAgAEX/fpxcXE6ePCgOnXq1OD+2NhY1dbWqqysTP3792/S9wQAANAQbnQOAACate7du2vMmDF6+eWXncYff/xx5eXlaebMmTp8+LD+/ve/69VXX3Vc6hcVFaU77rhDDz74oAoKClRYWKhJkybJx8fHcYyEhATZbDYlJSXpk08+0YkTJ/Tpp5/qmWee0a5duxrM88c//lEWi0X333+/Dh48qI8//ljPP/+805yUlBR99913uvfee7Vz504dO3ZMubm5Gj9+vGpra+Xv76/k5GQ98cQT2rBhgw4cOKCJEyeqRYsWslgsF/15PPnkk/r000+VmpqqoqIiHTlyRKtXr3bc6Lxz584aM2aMxo4dq/fff1/Hjx/Xjh07lJmZqY8++uiSf/4AAKD5opQCAADN3owZM1RXV+c0FhcXp7ffflsrV65Ut27dNG3aNM2YMcPpMr+srCyFhYXp9ttv1913360HHnhAwcHBjv0Wi0Uff/yxBgwYoPHjx6tz584aPXq0Tp48KavV2mAWPz8/rVmzRvv27VNsbKyeeeaZepfphYWFaevWraqtrdWQIUPUvXt3paWlqXXr1mrR4qdf71588UXZbDbdddddSkhIUL9+/RQTE+N0r6qG9OjRQ/n5+Tp8+LD69++v2NhYTZs2zemm5llZWRo7dqwef/xxRUVFKSkpyemsLAAAgKbg6XsAAADNQHV1tdq2basXXnhBEydONDsOAAAA95QCAAC4Hu3evVuff/65+vTpo4qKCs2YMUOS6j1REAAAwCyUUgAAANep559/XsXFxfL09FR8fLw2b96sG264wexYAAAAkrh8DwAAAAAAACbgRucAAAAAAAAwHKUUAAAAAAAADEcpBQAAAAAAAMNRSgEAAAAAAMBwlFIAAAAAAAAwHKUUAAAAAAAADEcpBQAAAAAAAMNRSgEAAAAAAMBwlFIAAAAAAAAw3P8Bk5rffsJ/yA0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils import degree\n",
    "from collections import Counter\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    return (sum(y_pred == y_true) / len(y_true))*100\n",
    "\n",
    "# Get model's classifications\n",
    "out = gat(data.x, data.edge_index)\n",
    "\n",
    "# Calculate the degree of each node\n",
    "degrees = degree(data.edge_index[0]).numpy()\n",
    "# Select degrees of nodes in test set\n",
    "degrees=degrees[data.test_mask.numpy()]\n",
    "\n",
    "# Store accuracy scores and sample sizes\n",
    "accuracies = []\n",
    "sizes = []\n",
    "\n",
    "probas = torch.nn.functional.softmax(out, dim=1)  # Convert logits to probabilities\n",
    "pred = probas.argmax(dim=1)\n",
    "\n",
    "# Test data\n",
    "true_labels = data.y[data.test_mask].cpu().numpy()\n",
    "predicted_labels = pred[data.test_mask].cpu().numpy()\n",
    "\n",
    "# Accuracy for degrees between 0 and 5\n",
    "for i in range(1, 10):\n",
    "    mask = np.where(degrees == i)[0]\n",
    "    accuracies.append(accuracy(predicted_labels[mask], true_labels[mask]))\n",
    "    sizes.append(len(mask))\n",
    "\n",
    "# Accuracy for degrees > 10\n",
    "mask = np.where(degrees > 10)[0]\n",
    "accuracies.append(accuracy(out.argmax(dim=1)[mask], data.y[mask]))\n",
    "sizes.append(len(mask))\n",
    "\n",
    "# Bar plot\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "ax.set_xlabel('Node degree')\n",
    "ax.set_ylabel('Accuracy')\n",
    "plt.bar(['1','2','3','4','5','6','7','8','9','10+'], accuracies, width=0.2, color='black', edgecolor='black')\n",
    "for i in range(0, 10):\n",
    "    plt.text(i, accuracies[i], f'{accuracies[i]:.2f}%', ha='center', color='black')\n",
    "for i in range(0, 10):\n",
    "    plt.text(i, accuracies[i]//2, sizes[i], ha='center', color='white')\n",
    "\n",
    "plt.title('Accuracy of GAT Model with Adam Optimizer on Cora Test Set by Node Degree')\n",
    "plt.tight_layout()\n",
    "plt.savefig('GAT_Cora_Adam_Accuracy_by_Degree.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75111d12-f4e1-4854-9e0c-c8cc0ed4eda7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
